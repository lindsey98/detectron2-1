{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overall workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Feed into element detector \n",
    "- Feed into credential classifier\n",
    "- Select suspicious data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../fig/example2.png\" style=\"width:2000px;height:350px\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('..')\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2_1.datasets import WebMapper\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import funcy\n",
    "from IPython.display import clear_output\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from pycocotools import cocoeval, coco\n",
    "from detectron2.data import build_detection_test_loader, MetadataCatalog, DatasetCatalog\n",
    "import numpy as np\n",
    "import tldextract\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "from collections import OrderedDict\n",
    "import random\n",
    "import shutil\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from credential import *\n",
    "from element_detector import *\n",
    "from detectron2_1.AL.AL_select import topn, kmeans_plus, core_set\n",
    "from layout_matcher.heuristic import layout_heuristic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ele_cfg, ele_model = element_config(rcnn_weights_path = 'output/website_lr0.001/model_final.pth', \n",
    "                                    rcnn_cfg_path='configs/faster_rcnn_web.yaml')\n",
    "\n",
    "cls_model = credential_config_screenshot(checkpoint='credential_classifier/output/screenshot/screenshot/BiT-M-R50x1_0.01.pth.tar')\n",
    "# cls_model = credential_config(checkpoint='credential_classifier/output/website_finetune/websiteV2/FCMaxV2_0.005.pth.tar')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get uncertainty and feature embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47713/47713 [02:48<00:00, 283.88it/s]\n"
     ]
    }
   ],
   "source": [
    "for file in tqdm(os.listdir('datasets/datasets/AL_pool_imgs/')):\n",
    "    if file in os.listdir('datasets/train_imgs/'):\n",
    "        print(file, \" in training\")\n",
    "    if file in os.listdir('datasets/val_imgs/'):\n",
    "        print(file, \" in validation\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 31172/47713 [2:35:46<1:14:07,  3.72it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 86%|████████▋ | 41264/47713 [3:27:02<31:34,  3.40it/s]  IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "entropy_agg = []\n",
    "margin_agg = []\n",
    "feature_agg = []\n",
    "\n",
    "for file in tqdm(os.listdir('datasets/datasets/AL_pool_imgs/')):\n",
    "    \n",
    "    img_path = os.path.join('datasets/datasets/AL_pool_imgs/', file)\n",
    "\n",
    "    pred_classes, pred_boxes, pred_scores = element_recognition(img=img_path, model=ele_model)\n",
    "\n",
    "    cls_pred, cls_conf, feature = credential_classifier_al_screenshot(img_path, cls_model)\n",
    "    \n",
    "    cls_conf = cls_conf[0].numpy()\n",
    "    \n",
    "    # entropy: higher --> uncertain\n",
    "    entropy = -np.sum(cls_conf * np.log2(cls_conf), axis=-1).item() \n",
    "    # 1 - (top1-top2): higher --> uncertain\n",
    "    margin = 1. - (cls_conf[cls_conf.argsort()[::-1][0]] - cls_conf[cls_conf.argsort()[::-1][1]]) \n",
    "    \n",
    "    entropy_agg.append(entropy)\n",
    "    margin_agg.append(margin)\n",
    "    feature_agg.append(feature.detach().cpu().numpy())\n",
    "    assert len(entropy_agg) == len(margin_agg) and len(margin_agg) == len(feature_agg)\n",
    "    assert feature_agg[-1].shape[-1] == 2048\n",
    "#     assert feature_agg[-1].shape[-1] == 16\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2048,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_agg[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "entropy_agg = np.asarray(entropy_agg)\n",
    "margin_agg = np.asarray(margin_agg)\n",
    "feature_agg = np.asarray(feature_agg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47713"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(entropy_agg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47713,)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entropy_agg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47713, 2048)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_agg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_agg = np.squeeze(feature_agg, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('./results/entropy_al.npy', entropy_agg)\n",
    "np.save('./results/margin_al.npy', margin_agg)\n",
    "np.save('./results/feature_al.npy', feature_agg)\n",
    "np.save('./results/al_files.npy', np.asarray(os.listdir('datasets/datasets/AL_pool_imgs/')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TopN / Core Set / Kmeans++ select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity computation finished\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "4100\n",
      "4200\n",
      "4300\n",
      "4400\n",
      "4500\n",
      "4600\n",
      "4700\n",
      "4800\n",
      "4900\n"
     ]
    }
   ],
   "source": [
    "c_sets = core_set(S=entropy_agg, feat=feature_agg, N=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(c_sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('./results/entropy_select5000_coreset.npy', c_sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_imgs = np.asarray(os.listdir('datasets/datasets/AL_pool_imgs/'))[np.asarray(c_sets)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists('./results/selected_img.txt'):\n",
    "    os.unlink('./results/selected_img.txt')\n",
    "    \n",
    "for img in tqdm(selected_imgs):\n",
    "    with open('./results/selected_img.txt', 'a+') as f:\n",
    "        f.write(img)\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "os.makedirs('datasets/datasets/AL_selected', exist_ok=True)\n",
    "\n",
    "for img in tqdm(selected_imgs):\n",
    "    shutil.copyfile(os.path.join('datasets/datasets/AL_pool_imgs/', img), \n",
    "                    os.path.join('datasets/datasets/AL_selected', img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar -czvf datasets/datasets/AL_selected.tar.gz datasets/datasets/AL_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar -czvf datasets/AL_pool_imgs.tar.gz datasets/AL_pool_imgs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization of selected images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_sets_copy = np.load('./results/entropy_select5000_coreset_grid.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_imgs = np.asarray(os.listdir('datasets/datasets/AL_pool_imgs/'))[np.asarray(c_sets_copy)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_dict = {0:'credential', 1:'noncredential'}\n",
    "selected_imgs = os.listdir('./datasets/datasets/AL_selected/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(selected_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree('./datasets/datasets/AL_selected_noncredential_grid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Filter some noncredential page by looking at input box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first-step categorization\n",
    "# os.makedirs('./datasets/datasets/AL_selected_credential_grid', exist_ok=True)\n",
    "os.makedirs('./datasets/datasets/AL_selected_noncredential', exist_ok=True)\n",
    "\n",
    "for path in tqdm(selected_imgs):\n",
    "    img_path = os.path.join('./datasets/datasets/AL_selected/', path)\n",
    "    # element detector\n",
    "    pred_classes, pred_boxes, pred_scores = element_recognition(img=img_path,\n",
    "                                                                model=ele_model)\n",
    "    # crp heuristic\n",
    "    pattern_ct, len_input = layout_heuristic(pred_boxes, pred_classes)\n",
    "    if len_input == 0:\n",
    "        rule_pred = 1\n",
    "        shutil.copyfile(img_path, \n",
    "                        os.path.join('./datasets/datasets/AL_selected_noncredential', path))        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Parse the rest images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# left-out images\n",
    "os.makedirs('./datasets/datasets/AL_selected_label', exist_ok=True)\n",
    "\n",
    "for img in os.listdir('datasets/datasets/AL_selected/'):\n",
    "    if img in os.listdir('datasets/datasets/AL_selected_noncredential'):\n",
    "        print(img)\n",
    "    else:\n",
    "        shutil.copyfile(os.path.join('datasets/datasets/AL_selected', img), \n",
    "                        os.path.join('datasets/datasets/AL_selected_label', img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar -czvf datasets/datasets/AL_selected_label.tar.gz datasets/datasets/AL_selected_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Mannual label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Remove correct and high confidence predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [02:47<00:00, 29.86it/s]\n"
     ]
    }
   ],
   "source": [
    "ct = 0\n",
    "for img in tqdm(os.listdir('datasets/datasets/AL_selected/')):\n",
    "    if img in os.listdir('datasets/datasets/AL_selected_credential/'):\n",
    "#         print(img)\n",
    "        continue\n",
    "    if img in os.listdir('datasets/datasets/AL_selected_noncredential/'):\n",
    "#         print(img)\n",
    "        continue\n",
    "    else:\n",
    "#         ct += 1\n",
    "        shutil.copyfile(os.path.join('datasets/datasets/AL_selected', img), \n",
    "                        os.path.join('datasets/datasets/AL_selected_noncredential', img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1474/1474 [04:38<00:00,  5.30it/s]\n"
     ]
    }
   ],
   "source": [
    "ct = 0\n",
    "for path in tqdm(os.listdir('./datasets/datasets/AL_selected_credential/')):\n",
    "    img_path = os.path.join('./datasets/datasets/AL_selected_credential/', path)\n",
    "    # element detector\n",
    "    pred_classes, pred_boxes, pred_scores = element_recognition(img=img_path,\n",
    "                                                                model=ele_model)\n",
    "    # crp classifier\n",
    "    cls_pred, cls_conf, feature = credential_classifier_al_screenshot(img_path, cls_model)\n",
    "    \n",
    "     # only check high confidence ones, low confidence ones all keep\n",
    "    if torch.max(cls_conf).item() > 0.8: \n",
    "        if cls_pred == 0: #分对了\n",
    "            ct += 1\n",
    "            os.unlink(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "716"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3526/3526 [14:44<00:00,  3.99it/s]\n"
     ]
    }
   ],
   "source": [
    "ct = 0\n",
    "for path in tqdm(os.listdir('./datasets/datasets/AL_selected_noncredential/')):\n",
    "    img_path = os.path.join('./datasets/datasets/AL_selected_noncredential/', path)\n",
    "    # element detector\n",
    "    pred_classes, pred_boxes, pred_scores = element_recognition(img=img_path,\n",
    "                                                                model=ele_model)\n",
    "    # crp classifier\n",
    "    cls_pred, cls_conf, feature = credential_classifier_al_screenshot(img_path, cls_model)\n",
    "    \n",
    "     # only check high confidence ones, low confidence ones all keep\n",
    "    if torch.max(cls_conf).item() > 0.8: \n",
    "        if cls_pred == 1: #分对了\n",
    "            ct += 1\n",
    "            os.unlink(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2016"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.hist(num_boxes)\n",
    "# plt.title('Distribution of number of predicted boxes')\n",
    "# plt.show()\n",
    "# plt.hist(cre_preds)\n",
    "# plt.title('Distribution of credential/noncredential class prediction')\n",
    "# plt.show()\n",
    "# plt.hist(cre_confs)\n",
    "# plt.title('Distribution of credential classifier prediction confidence')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ct = 0\n",
    "# for img in os.listdir('datasets/datasets/AL_selected/'):\n",
    "#     if img in os.listdir('datasets/datasets/AL_selected_noncredential/'):\n",
    "# #         print(img)\n",
    "#         ct += 1\n",
    "#     else:\n",
    "#         shutil.copyfile(os.path.join('datasets/datasets/AL_selected', img), \n",
    "#                         os.path.join('datasets/datasets/AL_selected_credential', img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge with existing training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create new coord file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "type_dict = {0:'logo', 1:'input', 2:'button', 3:'label', 4:'block'}\n",
    "\n",
    "for path in os.listdir('./datasets/datasets/AL_selected_noncredential/'):\n",
    "    img_path = os.path.join('./datasets/datasets/AL_selected_noncredential/', path)\n",
    "    # element detector\n",
    "    pred_classes, pred_boxes, pred_scores = element_recognition(img=img_path,\n",
    "                                                                model=ele_model)\n",
    "    pred_classes = pred_classes.numpy()\n",
    "    pred_boxes = pred_boxes.numpy()\n",
    "    \n",
    "    for j in range(len(pred_boxes)):\n",
    "        with open('./datasets/train_al_coords2.txt', 'a+') as f:\n",
    "            f.write(path.split('.png')[0] + '\\t')\n",
    "            f.write('(' + ','.join(list(map(str, pred_boxes[j]))) + ')' + '\\t') \n",
    "            f.write(type_dict[pred_classes[j]] + '\\t')\n",
    "            f.write('noncredential')\n",
    "            f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in os.listdir('./datasets/datasets/AL_selected_credential/'):\n",
    "    img_path = os.path.join('./datasets/datasets/AL_selected_credential/', path)\n",
    "    # element detector\n",
    "    pred_classes, pred_boxes, pred_scores = element_recognition(img=img_path,\n",
    "                                                                model=ele_model)\n",
    "    pred_classes = pred_classes.numpy()\n",
    "    pred_boxes = pred_boxes.numpy()\n",
    "    \n",
    "    for j in range(len(pred_boxes)):\n",
    "        with open('./datasets/train_al_coords2.txt', 'a+') as f:\n",
    "            f.write(path.split('.png')[0] + '\\t')\n",
    "            f.write('(' + ','.join(list(map(str, pred_boxes[j]))) + ')' + '\\t') \n",
    "            f.write(type_dict[pred_classes[j]] + '\\t')\n",
    "            f.write('credential')\n",
    "            f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for path in os.listdir('./datasets/datasets/AL_selected_credential_grid/'):\n",
    "#     with open('./datasets/train_al_grid_coords.txt', 'a+') as f:\n",
    "#         f.write(path.split('.png')[0])\n",
    "#         f.write('\\t\\t\\t') # no coordinates available\n",
    "#         f.write('credential')\n",
    "#         f.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Merge with existing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2268"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(os.listdir('./datasets/datasets/AL_selected_noncredential/')) + \\\n",
    "len(os.listdir('./datasets/datasets/AL_selected_credential/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
