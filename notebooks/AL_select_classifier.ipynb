{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overall workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Feed into element detector \n",
    "- Feed into credential classifier\n",
    "- Select suspicious data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../fig/example2.png\" style=\"width:2000px;height:350px\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('..')\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2_1.datasets import WebMapper\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import funcy\n",
    "from IPython.display import clear_output\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from pycocotools import cocoeval, coco\n",
    "from detectron2.data import build_detection_test_loader, MetadataCatalog, DatasetCatalog\n",
    "import numpy as np\n",
    "import tldextract\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "from collections import OrderedDict\n",
    "import random\n",
    "import shutil\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from credential import *\n",
    "from element_detector import *\n",
    "from detectron2_1.AL.AL_select import topn, kmeans_plus, core_set\n",
    "from layout_matcher.heuristic import layout_heuristic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ele_cfg, ele_model = element_config(rcnn_weights_path = 'output/website_lr0.001/model_final.pth', \n",
    "                                    rcnn_cfg_path='configs/faster_rcnn_web.yaml')\n",
    "\n",
    "# cls_model = credential_config_screenshot(checkpoint='credential_classifier/output/screenshot/screenshot/BiT-M-R50x1_0.005.pth.tar')\n",
    "cls_model = credential_config(checkpoint='credential_classifier/FCMax_0.05.pth.tar')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get uncertainty and feature embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entropy_agg = []\n",
    "margin_agg = []\n",
    "feature_agg = []\n",
    "\n",
    "for file in tqdm(os.listdir('datasets/datasets/AL_pool_imgs/')):\n",
    "    img_path = os.path.join('datasets/datasets/AL_pool_imgs/', file)\n",
    "\n",
    "    pred_classes, pred_boxes, pred_scores = element_recognition(img=img_path, model=ele_model)\n",
    "\n",
    "    cls_pred, cls_conf, feature = credential_classifier_al(img_path, pred_boxes, pred_classes, cls_model)\n",
    "    \n",
    "    cls_conf = cls_conf[0].numpy()\n",
    "    \n",
    "    # entropy: higher --> uncertain\n",
    "    entropy = -np.sum(cls_conf * np.log2(cls_conf), axis=-1).item() \n",
    "    # 1 - (top1-top2): higher --> uncertain\n",
    "    margin = 1. - (cls_conf[cls_conf.argsort()[::-1][0]] - cls_conf[cls_conf.argsort()[::-1][1]]) \n",
    "    \n",
    "    entropy_agg.append(entropy)\n",
    "    margin_agg.append(margin)\n",
    "    feature_agg.append(feature.detach().cpu().numpy())\n",
    "    assert len(entropy_agg) == len(margin_agg) and len(margin_agg) == len(feature_agg)\n",
    "#     assert feature_agg[-1].shape[-1] == 2048\n",
    "    assert feature_agg[-1].shape[-1] == 16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entropy_agg = np.asarray(entropy_agg)\n",
    "margin_agg = np.asarray(margin_agg)\n",
    "feature_agg = np.asarray(feature_agg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(entropy_agg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entropy_agg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_agg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_agg = np.squeeze(feature_agg, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('./results/entropy_al_grid.npy', entropy_agg)\n",
    "np.save('./results/margin_al_grid.npy', margin_agg)\n",
    "np.save('./results/feature_al_grid.npy', feature_agg)\n",
    "np.save('./results/al_files_grid.npy', np.asarray(os.listdir('datasets/datasets/AL_pool_imgs/')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TopN / Core Set / Kmeans++ select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "c_sets = core_set(S=entropy_agg, feat=feature_agg, N=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(c_sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('./results/entropy_select5000_coreset_grid.npy', c_sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_imgs = np.asarray(os.listdir('datasets/datasets/AL_pool_imgs/'))[np.asarray(c_sets)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists('./results/selected_img_grid.txt'):\n",
    "    os.unlink('./results/selected_img_grid.txt')\n",
    "    \n",
    "for img in tqdm(selected_imgs):\n",
    "    with open('./results/selected_img_grid.txt', 'a+') as f:\n",
    "        f.write(img)\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "os.makedirs('datasets/datasets/AL_selected_grid', exist_ok=True)\n",
    "\n",
    "for img in tqdm(selected_imgs):\n",
    "    shutil.copyfile(os.path.join('datasets/datasets/AL_pool_imgs/', img), \n",
    "                    os.path.join('datasets/datasets/AL_selected_grid', img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar -czvf datasets/datasets/AL_selected.tar.gz datasets/datasets/AL_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar -czvf datasets/AL_pool_imgs.tar.gz datasets/AL_pool_imgs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization of selected images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_sets_copy = np.load('./results/entropy_select5000_coreset_grid.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_imgs = np.asarray(os.listdir('datasets/datasets/AL_pool_imgs/'))[np.asarray(c_sets_copy)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_dict = {0:'credential', 1:'noncredential'}\n",
    "selected_imgs = os.listdir('./datasets/datasets/AL_selected/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(selected_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree('./datasets/datasets/AL_selected_noncredential_grid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [10:45<00:00,  7.75it/s]  \n"
     ]
    }
   ],
   "source": [
    "# first-step categorization\n",
    "# os.makedirs('./datasets/datasets/AL_selected_credential_grid', exist_ok=True)\n",
    "os.makedirs('./datasets/datasets/AL_selected_noncredential_grid', exist_ok=True)\n",
    "\n",
    "for path in tqdm(selected_imgs):\n",
    "    img_path = os.path.join('./datasets/datasets/AL_selected_grid/', path)\n",
    "    # element detector\n",
    "    pred_classes, pred_boxes, pred_scores = element_recognition(img=img_path,\n",
    "                                                                model=ele_model)\n",
    "    # crp heuristic\n",
    "    pattern_ct, len_input = layout_heuristic(pred_boxes, pred_classes)\n",
    "    if len_input == 0:\n",
    "        rule_pred = 1\n",
    "        shutil.copyfile(img_path, \n",
    "                        os.path.join('./datasets/datasets/AL_selected_noncredential_grid', path))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# left-out images\n",
    "os.makedirs('./datasets/datasets/AL_selected_label_grid', exist_ok=True)\n",
    "\n",
    "for img in os.listdir('datasets/datasets/AL_selected_grid/'):\n",
    "    if img in os.listdir('datasets/datasets/AL_selected_noncredential_grid/'):\n",
    "        print(img)\n",
    "    else:\n",
    "        shutil.copyfile(os.path.join('datasets/datasets/AL_selected_grid', img), \n",
    "                        os.path.join('datasets/datasets/AL_selected_label_grid', img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar -czvf datasets/datasets/AL_selected_label_grid.tar.gz datasets/datasets/AL_selected_label_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [01:13<00:00, 67.81it/s] \n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for img in tqdm(os.listdir('datasets/datasets/AL_selected_grid/')):\n",
    "    if img in os.listdir('datasets/datasets/AL_selected_credential_grid/'):\n",
    "        continue\n",
    "    if img in os.listdir('datasets/datasets/AL_selected_noncredential_grid/'):\n",
    "        continue\n",
    "    else:\n",
    "        shutil.copyfile(os.path.join('datasets/datasets/AL_selected_grid', img), \n",
    "                        os.path.join('datasets/datasets/AL_selected_noncredential_grid', img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_boxes = []\n",
    "# cre_preds = []\n",
    "# cre_confs = []\n",
    "\n",
    "# for path in tqdm(selected_imgs):\n",
    "#     img_path = os.path.join('./datasets/datasets/AL_selected/', path)\n",
    "#     # element detector\n",
    "#     pred_classes, pred_boxes, pred_scores = element_recognition(img=img_path,\n",
    "#                                                                 model=ele_model)\n",
    "#     # crp classifier\n",
    "#     cls_pred, cls_conf, feature = credential_classifier_al(img_path, pred_boxes, pred_classes, cls_model)\n",
    "#     # crp heuristic\n",
    "#     pattern_ct, len_input = layout_heuristic(pred_boxes, pred_classes)\n",
    "#     if len_input == 0:\n",
    "#         rule_pred = 1\n",
    "#     elif pattern_ct >= 2:\n",
    "#         rule_pred = 0\n",
    "#     else:\n",
    "#         rule_pred = cls_pred\n",
    "    \n",
    "#     num_boxes.append(len(pred_boxes))\n",
    "#     cre_preds.append(cls_pred)\n",
    "#     cre_confs.append(torch.max(cls_conf).item())\n",
    "    \n",
    "#     # If credential heuristic prediction is not equal to classifier prediction --> wrong prediction by classifier\n",
    "#     if rule_pred != cls_pred:\n",
    "#         del cls_pred, cls_conf, feature, pred_classes, pred_boxes, pred_scores, rule_pred\n",
    "#         continue\n",
    "\n",
    "    # only check high confidence ones, low confidence ones all keep\n",
    "#     if torch.max(cls_conf).item() > 0.8: \n",
    "                \n",
    "#         check = cv2.imread(img_path)\n",
    "#         for j, box in enumerate(pred_boxes):\n",
    "#             cv2.rectangle(check, (box[0], box[1]), (box[2], box[3]), (36, 255, 12), 2)\n",
    "#             cv2.putText(check, str(pred_classes[j].item()), (box[0], box[1]), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
    "    \n",
    "#         plt.figure(figsize=(20,20))\n",
    "#         plt.imshow(check[:, :, ::-1])\n",
    "#         plt.title('Prediction category: {} with prediction confidence: {:.4f}'.format(class_dict[cls_pred], torch.max(cls_conf).item()))\n",
    "#         plt.show()\n",
    "        \n",
    "#         # high confidence keep only wrong prediction\n",
    "#         y = input() \n",
    "#         if y == 'r':\n",
    "#             os.unlink(img_path) # remove correct predicted ones\n",
    "\n",
    "#         clear_output()\n",
    "        \n",
    "#     del cls_pred, cls_conf, feature, pred_classes, pred_boxes, pred_scores, rule_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1750/1750 [04:12<00:00,  6.93it/s]\n"
     ]
    }
   ],
   "source": [
    "ct = 0\n",
    "for path in tqdm(os.listdir('./datasets/datasets/AL_selected_credential_grid/')):\n",
    "    img_path = os.path.join('./datasets/datasets/AL_selected_credential_grid/', path)\n",
    "    # element detector\n",
    "    pred_classes, pred_boxes, pred_scores = element_recognition(img=img_path,\n",
    "                                                                model=ele_model)\n",
    "    # crp classifier\n",
    "    cls_pred, cls_conf, feature = credential_classifier_al(img_path, pred_boxes, pred_classes, cls_model)\n",
    "    \n",
    "     # only check high confidence ones, low confidence ones all keep\n",
    "    if torch.max(cls_conf).item() > 0.8: \n",
    "        if cls_pred == 0: #分对了\n",
    "            ct += 1\n",
    "            os.unlink(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3250/3250 [07:44<00:00,  7.00it/s]\n"
     ]
    }
   ],
   "source": [
    "ct = 0\n",
    "for path in tqdm(os.listdir('./datasets/datasets/AL_selected_noncredential_grid/')):\n",
    "    img_path = os.path.join('./datasets/datasets/AL_selected_noncredential_grid/', path)\n",
    "    # element detector\n",
    "    pred_classes, pred_boxes, pred_scores = element_recognition(img=img_path,\n",
    "                                                                model=ele_model)\n",
    "    # crp classifier\n",
    "    cls_pred, cls_conf, feature = credential_classifier_al(img_path, pred_boxes, pred_classes, cls_model)\n",
    "    \n",
    "     # only check high confidence ones, low confidence ones all keep\n",
    "    if torch.max(cls_conf).item() > 0.8: \n",
    "        if cls_pred == 1: #分对了\n",
    "            ct += 1\n",
    "            os.unlink(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.hist(num_boxes)\n",
    "# plt.title('Distribution of number of predicted boxes')\n",
    "# plt.show()\n",
    "# plt.hist(cre_preds)\n",
    "# plt.title('Distribution of credential/noncredential class prediction')\n",
    "# plt.show()\n",
    "# plt.hist(cre_confs)\n",
    "# plt.title('Distribution of credential classifier prediction confidence')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ct = 0\n",
    "# for img in os.listdir('datasets/datasets/AL_selected/'):\n",
    "#     if img in os.listdir('datasets/datasets/AL_selected_noncredential/'):\n",
    "# #         print(img)\n",
    "#         ct += 1\n",
    "#     else:\n",
    "#         shutil.copyfile(os.path.join('datasets/datasets/AL_selected', img), \n",
    "#                         os.path.join('datasets/datasets/AL_selected_credential', img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge with existing training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create new coord file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "type_dict = {0:'logo', 1:'input', 2:'button', 3:'label', 4:'block'}\n",
    "\n",
    "for path in os.listdir('./datasets/datasets/AL_selected_noncredential_grid/'):\n",
    "    img_path = os.path.join('./datasets/datasets/AL_selected_noncredential_grid/', path)\n",
    "    # element detector\n",
    "    pred_classes, pred_boxes, pred_scores = element_recognition(img=img_path,\n",
    "                                                                model=ele_model)\n",
    "    pred_classes = pred_classes.numpy()\n",
    "    pred_boxes = pred_boxes.numpy()\n",
    "    \n",
    "    for j in range(len(pred_boxes)):\n",
    "        with open('./datasets/train_al_grid_coords.txt', 'a+') as f:\n",
    "            f.write(path.split('.png')[0] + '\\t')\n",
    "            f.write('(' + ','.join(list(map(str, pred_boxes[j]))) + ')' + '\\t') \n",
    "            f.write(type_dict[pred_classes[j]] + '\\t')\n",
    "            f.write('noncredential')\n",
    "            f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in os.listdir('./datasets/datasets/AL_selected_credential_grid/'):\n",
    "    img_path = os.path.join('./datasets/datasets/AL_selected_credential_grid/', path)\n",
    "    # element detector\n",
    "    pred_classes, pred_boxes, pred_scores = element_recognition(img=img_path,\n",
    "                                                                model=ele_model)\n",
    "    pred_classes = pred_classes.numpy()\n",
    "    pred_boxes = pred_boxes.numpy()\n",
    "    \n",
    "    for j in range(len(pred_boxes)):\n",
    "        with open('./datasets/train_al_grid_coords.txt', 'a+') as f:\n",
    "            f.write(path.split('.png')[0] + '\\t')\n",
    "            f.write('(' + ','.join(list(map(str, pred_boxes[j]))) + ')' + '\\t') \n",
    "            f.write(type_dict[pred_classes[j]] + '\\t')\n",
    "            f.write('credential')\n",
    "            f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in os.listdir('./datasets/datasets/AL_selected_credential_grid/'):\n",
    "    with open('./datasets/train_al_grid_coords.txt', 'a+') as f:\n",
    "        f.write(path.split('.png')[0])\n",
    "        f.write('\\t\\t\\t') # no coordinates available\n",
    "        f.write('credential')\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Merge with existing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2099"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(os.listdir('./datasets/datasets/AL_selected_noncredential_grid/')) + len(os.listdir('./datasets/datasets/AL_selected_credential_grid/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
