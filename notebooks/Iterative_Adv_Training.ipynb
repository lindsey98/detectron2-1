{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterative Adv Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For iter in Range(20):\n",
    "-       Step 1: Generate training adv examples to 1) overwrite shot_adv.png 2) create coco_perturb_train.json\n",
    "-       Step 2: Mix downsampled normal training data with perturbed training data (4:1) and create coco_adv_mix.json\n",
    "-       Step 3: Evaluate training Acc on all clean+adv examples (9 metrics)\n",
    "-       Step 4: Gerenate testing adv examples .... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycocotools.coco import COCO\n",
    "from pycocotools.cocoeval import COCOeval\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/l/liny/yizhe/code/detectron2-1\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=10.52s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.63s)\n",
      "creating index...\n",
      "index created!\n",
      "Command Line Args: Namespace(config_file='configs/faster_rcnn_adv_eval_test.yaml', dist_url='tcp://127.0.0.1:49923', eval_only=True, machine_rank=0, num_gpus=1, num_machines=1, opts=['MODEL.WEIGHTS', 'output/adv_0/model_final.pth', 'OUTPUT_DIR', 'output/adv_0'], resume=False)\n",
      "\u001b[32m[09/09 10:55:14 detectron2]: \u001b[0mRank of current process: 0. World size: 1\n",
      "\u001b[32m[09/09 10:55:15 detectron2]: \u001b[0mEnvironment info:\n",
      "----------------------  -------------------------------------------------------------------------------------------\n",
      "sys.platform            linux\n",
      "Python                  3.7.7 (default, Mar 23 2020, 22:36:06) [GCC 7.3.0]\n",
      "numpy                   1.18.1\n",
      "detectron2              0.1.3 @/home/l/liny/anaconda3/envs/mypy37/lib/python3.7/site-packages/detectron2\n",
      "Compiler                GCC 5.4\n",
      "CUDA compiler           CUDA 9.2\n",
      "detectron2 arch flags   sm_70\n",
      "DETECTRON2_ENV_MODULE   <not set>\n",
      "PyTorch                 1.5.0 @/home/l/liny/anaconda3/envs/mypy37/lib/python3.7/site-packages/torch\n",
      "PyTorch debug build     False\n",
      "GPU available           True\n",
      "GPU 0                   Tesla V100-PCIE-16GB\n",
      "CUDA_HOME               /usr/local/cuda-9.2\n",
      "Pillow                  7.0.0\n",
      "torchvision             0.6.0a0+82fd1c8 @/home/l/liny/anaconda3/envs/mypy37/lib/python3.7/site-packages/torchvision\n",
      "torchvision arch flags  sm_35, sm_50, sm_60, sm_70\n",
      "fvcore                  0.1.1.post20200618\n",
      "cv2                     4.3.0\n",
      "----------------------  -------------------------------------------------------------------------------------------\n",
      "PyTorch built with:\n",
      "  - GCC 7.3\n",
      "  - C++ Version: 201402\n",
      "  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v0.21.1 (Git Hash 7d2fd500bc78936d1d648ca713b901012f470dbc)\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
      "  - NNPACK is enabled\n",
      "  - CPU capability usage: AVX2\n",
      "  - CUDA Runtime 9.2\n",
      "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_37,code=compute_37\n",
      "  - CuDNN 7.6.3\n",
      "  - Magma 2.5.2\n",
      "  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_INTERNAL_THREADPOOL_IMPL -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, \n",
      "\n",
      "\u001b[32m[09/09 10:55:15 detectron2]: \u001b[0mCommand line arguments: Namespace(config_file='configs/faster_rcnn_adv_eval_test.yaml', dist_url='tcp://127.0.0.1:49923', eval_only=True, machine_rank=0, num_gpus=1, num_machines=1, opts=['MODEL.WEIGHTS', 'output/adv_0/model_final.pth', 'OUTPUT_DIR', 'output/adv_0'], resume=False)\n",
      "\u001b[32m[09/09 10:55:15 detectron2]: \u001b[0mContents of args.config_file=configs/faster_rcnn_adv_eval_test.yaml:\n",
      "_BASE_: \"./bases/Base-RCNN-FPN.yaml\"\n",
      "MODEL:\n",
      "  # COCO ResNet50 weights\n",
      "  WEIGHTS: \"./output/rcnn_bet365/model_final.pth\"\n",
      "  MASK_ON: False # Not doing segmentation\n",
      "  RESNETS:\n",
      "    DEPTH: 50 # ResNet50\n",
      "  ROI_HEADS:\n",
      "    NUM_CLASSES: 2 # Change to suit own task\n",
      "    # Can reduce this for lower memory/faster training; Default 512\n",
      "    BATCH_SIZE_PER_IMAGE: 512\n",
      "  BACKBONE:\n",
      "    FREEZE_AT: 2 # Default 2\n",
      "DATASETS:\n",
      "  TRAIN: (\"benign_adv\",)\n",
      "  TEST: (\"benign_adv_test\",)\n",
      "DATALOADER:\n",
      "  NUM_WORKERS: 0\n",
      "SOLVER:\n",
      "  IMS_PER_BATCH: 8 # Batch size; Default 16\n",
      "  BASE_LR: 0.00005\n",
      "  # (2/3, 8/9)\n",
      "  STEPS: (2000, 5000) # The iteration number to decrease learning rate by GAMMA.\n",
      "  MAX_ITER: 7000 # Number of training iterations\n",
      "  CHECKPOINT_PERIOD: 1000 # Saves checkpoint every number of steps\n",
      "INPUT:\n",
      "  MIN_SIZE_TRAIN: (640, 672, 704, 736, 768, 800) # Image input sizes\n",
      "TEST:\n",
      "  # The period (in terms of steps) to evaluate the model during training.\n",
      "  # Set to 0 to disable.\n",
      "  EVAL_PERIOD: 1000\n",
      "OUTPUT_DIR: \"./output/adv\" # Specify output directory\n",
      "\n",
      "\u001b[32m[09/09 10:55:15 detectron2]: \u001b[0mRunning with full config:\n",
      "CUDNN_BENCHMARK: False\n",
      "DATALOADER:\n",
      "  ASPECT_RATIO_GROUPING: True\n",
      "  FILTER_EMPTY_ANNOTATIONS: True\n",
      "  NUM_WORKERS: 0\n",
      "  REPEAT_THRESHOLD: 0.0\n",
      "  SAMPLER_TRAIN: TrainingSampler\n",
      "DATASETS:\n",
      "  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000\n",
      "  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000\n",
      "  PROPOSAL_FILES_TEST: ()\n",
      "  PROPOSAL_FILES_TRAIN: ()\n",
      "  TEST: ('benign_adv_test',)\n",
      "  TRAIN: ('benign_adv',)\n",
      "GLOBAL:\n",
      "  HACK: 1.0\n",
      "INPUT:\n",
      "  CROP:\n",
      "    ENABLED: False\n",
      "    SIZE: [0.9, 0.9]\n",
      "    TYPE: relative_range\n",
      "  FORMAT: BGR\n",
      "  MASK_FORMAT: polygon\n",
      "  MAX_SIZE_TEST: 1333\n",
      "  MAX_SIZE_TRAIN: 1333\n",
      "  MIN_SIZE_TEST: 800\n",
      "  MIN_SIZE_TRAIN: (640, 672, 704, 736, 768, 800)\n",
      "  MIN_SIZE_TRAIN_SAMPLING: choice\n",
      "MODEL:\n",
      "  ANCHOR_GENERATOR:\n",
      "    ANGLES: [[-90, 0, 90]]\n",
      "    ASPECT_RATIOS: [[0.5, 1.0, 2.0]]\n",
      "    NAME: DefaultAnchorGenerator\n",
      "    OFFSET: 0.0\n",
      "    SIZES: [[32], [64], [128], [256], [512]]\n",
      "  BACKBONE:\n",
      "    FREEZE_AT: 2\n",
      "    NAME: build_resnet_fpn_backbone\n",
      "  DEVICE: cuda\n",
      "  FPN:\n",
      "    FUSE_TYPE: sum\n",
      "    IN_FEATURES: ['res2', 'res3', 'res4', 'res5']\n",
      "    NORM: \n",
      "    OUT_CHANNELS: 256\n",
      "  KEYPOINT_ON: False\n",
      "  LOAD_PROPOSALS: False\n",
      "  MASK_ON: False\n",
      "  META_ARCHITECTURE: GeneralizedRCNN\n",
      "  PANOPTIC_FPN:\n",
      "    COMBINE:\n",
      "      ENABLED: True\n",
      "      INSTANCES_CONFIDENCE_THRESH: 0.5\n",
      "      OVERLAP_THRESH: 0.5\n",
      "      STUFF_AREA_LIMIT: 4096\n",
      "    INSTANCE_LOSS_WEIGHT: 1.0\n",
      "  PIXEL_MEAN: [103.53, 116.28, 123.675]\n",
      "  PIXEL_STD: [1.0, 1.0, 1.0]\n",
      "  PROPOSAL_GENERATOR:\n",
      "    MIN_SIZE: 0\n",
      "    NAME: RPN\n",
      "  RESNETS:\n",
      "    DEFORM_MODULATED: False\n",
      "    DEFORM_NUM_GROUPS: 1\n",
      "    DEFORM_ON_PER_STAGE: [False, False, False, False]\n",
      "    DEPTH: 50\n",
      "    NORM: FrozenBN\n",
      "    NUM_GROUPS: 1\n",
      "    OUT_FEATURES: ['res2', 'res3', 'res4', 'res5']\n",
      "    RES2_OUT_CHANNELS: 256\n",
      "    RES5_DILATION: 1\n",
      "    STEM_OUT_CHANNELS: 64\n",
      "    STRIDE_IN_1X1: True\n",
      "    WIDTH_PER_GROUP: 64\n",
      "  RETINANET:\n",
      "    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)\n",
      "    FOCAL_LOSS_ALPHA: 0.25\n",
      "    FOCAL_LOSS_GAMMA: 2.0\n",
      "    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']\n",
      "    IOU_LABELS: [0, -1, 1]\n",
      "    IOU_THRESHOLDS: [0.4, 0.5]\n",
      "    NMS_THRESH_TEST: 0.5\n",
      "    NUM_CLASSES: 80\n",
      "    NUM_CONVS: 4\n",
      "    PRIOR_PROB: 0.01\n",
      "    SCORE_THRESH_TEST: 0.05\n",
      "    SMOOTH_L1_LOSS_BETA: 0.1\n",
      "    TOPK_CANDIDATES_TEST: 1000\n",
      "  ROI_BOX_CASCADE_HEAD:\n",
      "    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))\n",
      "    IOUS: (0.5, 0.6, 0.7)\n",
      "  ROI_BOX_HEAD:\n",
      "    BBOX_REG_LOSS_TYPE: smooth_l1\n",
      "    BBOX_REG_LOSS_WEIGHT: 1.0\n",
      "    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)\n",
      "    CLS_AGNOSTIC_BBOX_REG: False\n",
      "    CONV_DIM: 256\n",
      "    FC_DIM: 1024\n",
      "    NAME: FastRCNNConvFCHead\n",
      "    NORM: \n",
      "    NUM_CONV: 0\n",
      "    NUM_FC: 2\n",
      "    POOLER_RESOLUTION: 7\n",
      "    POOLER_SAMPLING_RATIO: 0\n",
      "    POOLER_TYPE: ROIAlignV2\n",
      "    SMOOTH_L1_BETA: 0.0\n",
      "    TRAIN_ON_PRED_BOXES: False\n",
      "  ROI_HEADS:\n",
      "    BATCH_SIZE_PER_IMAGE: 512\n",
      "    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']\n",
      "    IOU_LABELS: [0, 1]\n",
      "    IOU_THRESHOLDS: [0.5]\n",
      "    NAME: StandardROIHeads\n",
      "    NMS_THRESH_TEST: 0.5\n",
      "    NUM_CLASSES: 2\n",
      "    POSITIVE_FRACTION: 0.25\n",
      "    PROPOSAL_APPEND_GT: True\n",
      "    SCORE_THRESH_TEST: 0.05\n",
      "  ROI_KEYPOINT_HEAD:\n",
      "    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)\n",
      "    LOSS_WEIGHT: 1.0\n",
      "    MIN_KEYPOINTS_PER_IMAGE: 1\n",
      "    NAME: KRCNNConvDeconvUpsampleHead\n",
      "    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True\n",
      "    NUM_KEYPOINTS: 17\n",
      "    POOLER_RESOLUTION: 14\n",
      "    POOLER_SAMPLING_RATIO: 0\n",
      "    POOLER_TYPE: ROIAlignV2\n",
      "  ROI_MASK_HEAD:\n",
      "    CLS_AGNOSTIC_MASK: False\n",
      "    CONV_DIM: 256\n",
      "    NAME: MaskRCNNConvUpsampleHead\n",
      "    NORM: \n",
      "    NUM_CONV: 4\n",
      "    POOLER_RESOLUTION: 14\n",
      "    POOLER_SAMPLING_RATIO: 0\n",
      "    POOLER_TYPE: ROIAlignV2\n",
      "  RPN:\n",
      "    BATCH_SIZE_PER_IMAGE: 256\n",
      "    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)\n",
      "    BOUNDARY_THRESH: -1\n",
      "    HEAD_NAME: StandardRPNHead\n",
      "    IN_FEATURES: ['p2', 'p3', 'p4', 'p5', 'p6']\n",
      "    IOU_LABELS: [0, -1, 1]\n",
      "    IOU_THRESHOLDS: [0.3, 0.7]\n",
      "    LOSS_WEIGHT: 1.0\n",
      "    NMS_THRESH: 0.7\n",
      "    POSITIVE_FRACTION: 0.5\n",
      "    POST_NMS_TOPK_TEST: 1000\n",
      "    POST_NMS_TOPK_TRAIN: 1000\n",
      "    PRE_NMS_TOPK_TEST: 1000\n",
      "    PRE_NMS_TOPK_TRAIN: 2000\n",
      "    SMOOTH_L1_BETA: 0.0\n",
      "  SEM_SEG_HEAD:\n",
      "    COMMON_STRIDE: 4\n",
      "    CONVS_DIM: 128\n",
      "    IGNORE_VALUE: 255\n",
      "    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']\n",
      "    LOSS_WEIGHT: 1.0\n",
      "    NAME: SemSegFPNHead\n",
      "    NORM: GN\n",
      "    NUM_CLASSES: 54\n",
      "  WEIGHTS: output/adv_0/model_final.pth\n",
      "OUTPUT_DIR: output/adv_0\n",
      "SEED: -1\n",
      "SOLVER:\n",
      "  BASE_LR: 5e-05\n",
      "  BIAS_LR_FACTOR: 1.0\n",
      "  CHECKPOINT_PERIOD: 1000\n",
      "  CLIP_GRADIENTS:\n",
      "    CLIP_TYPE: value\n",
      "    CLIP_VALUE: 1.0\n",
      "    ENABLED: False\n",
      "    NORM_TYPE: 2.0\n",
      "  GAMMA: 0.1\n",
      "  IMS_PER_BATCH: 8\n",
      "  LR_SCHEDULER_NAME: WarmupMultiStepLR\n",
      "  MAX_ITER: 7000\n",
      "  MOMENTUM: 0.9\n",
      "  NESTEROV: False\n",
      "  STEPS: (2000, 5000)\n",
      "  WARMUP_FACTOR: 0.001\n",
      "  WARMUP_ITERS: 1000\n",
      "  WARMUP_METHOD: linear\n",
      "  WEIGHT_DECAY: 0.0001\n",
      "  WEIGHT_DECAY_BIAS: 0.0001\n",
      "  WEIGHT_DECAY_NORM: 0.0\n",
      "TEST:\n",
      "  AUG:\n",
      "    ENABLED: False\n",
      "    FLIP: True\n",
      "    MAX_SIZE: 4000\n",
      "    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)\n",
      "  DETECTIONS_PER_IMAGE: 100\n",
      "  EVAL_PERIOD: 1000\n",
      "  EXPECTED_RESULTS: []\n",
      "  KEYPOINT_OKS_SIGMAS: []\n",
      "  PRECISE_BN:\n",
      "    ENABLED: False\n",
      "    NUM_ITER: 200\n",
      "VERSION: 2\n",
      "VIS_PERIOD: 0\n",
      "\u001b[32m[09/09 10:55:15 detectron2]: \u001b[0mFull config saved to output/adv_0/config.yaml\n",
      "\u001b[32m[09/09 10:55:15 d2.utils.env]: \u001b[0mUsing a generated random seed 16217106\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[09/09 10:55:19 d2.engine.defaults]: \u001b[0mModel:\r\n",
      "GeneralizedRCNN(\r\n",
      "  (backbone): FPN(\r\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\r\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\r\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\r\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\r\n",
      "    (top_block): LastLevelMaxPool()\r\n",
      "    (bottom_up): ResNet(\r\n",
      "      (stem): BasicStem(\r\n",
      "        (conv1): Conv2d(\r\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\r\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\r\n",
      "        )\r\n",
      "      )\r\n",
      "      (res2): Sequential(\r\n",
      "        (0): BottleneckBlock(\r\n",
      "          (shortcut): Conv2d(\r\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\r\n",
      "          )\r\n",
      "          (conv1): Conv2d(\r\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\r\n",
      "          )\r\n",
      "          (conv2): Conv2d(\r\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\r\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\r\n",
      "          )\r\n",
      "          (conv3): Conv2d(\r\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\r\n",
      "          )\r\n",
      "        )\r\n",
      "        (1): BottleneckBlock(\r\n",
      "          (conv1): Conv2d(\r\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\r\n",
      "          )\r\n",
      "          (conv2): Conv2d(\r\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\r\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\r\n",
      "          )\r\n",
      "          (conv3): Conv2d(\r\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\r\n",
      "          )\r\n",
      "        )\r\n",
      "        (2): BottleneckBlock(\r\n",
      "          (conv1): Conv2d(\r\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\r\n",
      "          )\r\n",
      "          (conv2): Conv2d(\r\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\r\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\r\n",
      "          )\r\n",
      "          (conv3): Conv2d(\r\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\r\n",
      "          )\r\n",
      "        )\r\n",
      "      )\r\n",
      "      (res3): Sequential(\r\n",
      "        (0): BottleneckBlock(\r\n",
      "          (shortcut): Conv2d(\r\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\r\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\r\n",
      "          )\r\n",
      "          (conv1): Conv2d(\r\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\r\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\r\n",
      "          )\r\n",
      "          (conv2): Conv2d(\r\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\r\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\r\n",
      "          )\r\n",
      "          (conv3): Conv2d(\r\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\r\n",
      "          )\r\n",
      "        )\r\n",
      "        (1): BottleneckBlock(\r\n",
      "          (conv1): Conv2d(\r\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\r\n",
      "          )\r\n",
      "          (conv2): Conv2d(\r\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\r\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\r\n",
      "          )\r\n",
      "          (conv3): Conv2d(\r\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\r\n",
      "          )\r\n",
      "        )\r\n",
      "        (2): BottleneckBlock(\r\n",
      "          (conv1): Conv2d(\r\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\r\n",
      "          )\r\n",
      "          (conv2): Conv2d(\r\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\r\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\r\n",
      "          )\r\n",
      "          (conv3): Conv2d(\r\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\r\n",
      "          )\r\n",
      "        )\r\n",
      "        (3): BottleneckBlock(\r\n",
      "          (conv1): Conv2d(\r\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\r\n",
      "          )\r\n",
      "          (conv2): Conv2d(\r\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\r\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\r\n",
      "          )\r\n",
      "          (conv3): Conv2d(\r\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\r\n",
      "          )\r\n",
      "        )\r\n",
      "      )\r\n",
      "      (res4): Sequential(\r\n",
      "        (0): BottleneckBlock(\r\n",
      "          (shortcut): Conv2d(\r\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\r\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\r\n",
      "          )\r\n",
      "          (conv1): Conv2d(\r\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\r\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\r\n",
      "          )\r\n",
      "          (conv2): Conv2d(\r\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\r\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\r\n",
      "          )\r\n",
      "          (conv3): Conv2d(\r\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\r\n",
      "          )\r\n",
      "        )\r\n",
      "        (1): BottleneckBlock(\r\n",
      "          (conv1): Conv2d(\r\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\r\n",
      "          )\r\n",
      "          (conv2): Conv2d(\r\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\r\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\r\n",
      "          )\r\n",
      "          (conv3): Conv2d(\r\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\r\n",
      "          )\r\n",
      "        )\r\n",
      "        (2): BottleneckBlock(\r\n",
      "          (conv1): Conv2d(\r\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\r\n",
      "          )\r\n",
      "          (conv2): Conv2d(\r\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\r\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\r\n",
      "          )\r\n",
      "          (conv3): Conv2d(\r\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\r\n",
      "          )\r\n",
      "        )\r\n",
      "        (3): BottleneckBlock(\r\n",
      "          (conv1): Conv2d(\r\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\r\n",
      "          )\r\n",
      "          (conv2): Conv2d(\r\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\r\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\r\n",
      "          )\r\n",
      "          (conv3): Conv2d(\r\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\r\n",
      "          )\r\n",
      "        )\r\n",
      "        (4): BottleneckBlock(\r\n",
      "          (conv1): Conv2d(\r\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\r\n",
      "          )\r\n",
      "          (conv2): Conv2d(\r\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\r\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\r\n",
      "          )\r\n",
      "          (conv3): Conv2d(\r\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\r\n",
      "          )\r\n",
      "        )\r\n",
      "        (5): BottleneckBlock(\r\n",
      "          (conv1): Conv2d(\r\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\r\n",
      "          )\r\n",
      "          (conv2): Conv2d(\r\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\r\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\r\n",
      "          )\r\n",
      "          (conv3): Conv2d(\r\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\r\n",
      "          )\r\n",
      "        )\r\n",
      "      )\r\n",
      "      (res5): Sequential(\r\n",
      "        (0): BottleneckBlock(\r\n",
      "          (shortcut): Conv2d(\r\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\r\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\r\n",
      "          )\r\n",
      "          (conv1): Conv2d(\r\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\r\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\r\n",
      "          )\r\n",
      "          (conv2): Conv2d(\r\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\r\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\r\n",
      "          )\r\n",
      "          (conv3): Conv2d(\r\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\r\n",
      "          )\r\n",
      "        )\r\n",
      "        (1): BottleneckBlock(\r\n",
      "          (conv1): Conv2d(\r\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\r\n",
      "          )\r\n",
      "          (conv2): Conv2d(\r\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\r\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\r\n",
      "          )\r\n",
      "          (conv3): Conv2d(\r\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\r\n",
      "          )\r\n",
      "        )\r\n",
      "        (2): BottleneckBlock(\r\n",
      "          (conv1): Conv2d(\r\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\r\n",
      "          )\r\n",
      "          (conv2): Conv2d(\r\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\r\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\r\n",
      "          )\r\n",
      "          (conv3): Conv2d(\r\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\r\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\r\n",
      "          )\r\n",
      "        )\r\n",
      "      )\r\n",
      "    )\r\n",
      "  )\r\n",
      "  (proposal_generator): RPN(\r\n",
      "    (rpn_head): StandardRPNHead(\r\n",
      "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\r\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "    )\r\n",
      "    (anchor_generator): DefaultAnchorGenerator(\r\n",
      "      (cell_anchors): BufferList()\r\n",
      "    )\r\n",
      "  )\r\n",
      "  (roi_heads): StandardROIHeads(\r\n",
      "    (box_pooler): ROIPooler(\r\n",
      "      (level_poolers): ModuleList(\r\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\r\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\r\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\r\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\r\n",
      "      )\r\n",
      "    )\r\n",
      "    (box_head): FastRCNNConvFCHead(\r\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\r\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\r\n",
      "    )\r\n",
      "    (box_predictor): FastRCNNOutputLayers(\r\n",
      "      (cls_score): Linear(in_features=1024, out_features=3, bias=True)\r\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=8, bias=True)\r\n",
      "    )\r\n",
      "  )\r\n",
      ")\r\n",
      "\u001b[32m[09/09 10:55:19 fvcore.common.checkpoint]: \u001b[0mLoading checkpoint from output/adv_0/model_final.pth\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[09/09 10:55:20 d2.data.datasets.coco]: \u001b[0mLoaded 1579 images in COCO format from data/benign_data/coco_perturbgt_test.json\n",
      "\u001b[32m[09/09 10:55:20 d2.data.build]: \u001b[0mDistribution of instances among all 2 categories:\n",
      "\u001b[36m|  category  | #instances   |  category  | #instances   |\n",
      "|:----------:|:-------------|:----------:|:-------------|\n",
      "|    box     | 2284         |    logo    | 1462         |\n",
      "|            |              |            |              |\n",
      "|   total    | 3746         |            |              |\u001b[0m\n",
      "\u001b[32m[09/09 10:55:20 d2.data.common]: \u001b[0mSerializing 1579 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[09/09 10:55:20 d2.data.common]: \u001b[0mSerialized dataset takes 0.45 MiB\n",
      "\u001b[32m[09/09 10:55:20 d2.evaluation.evaluator]: \u001b[0mStart inference on 1579 images\n",
      "\u001b[32m[09/09 10:55:25 d2.evaluation.evaluator]: \u001b[0mInference done 11/1579. 0.0440 s / img. ETA=0:10:40\n",
      "\u001b[32m[09/09 10:55:30 d2.evaluation.evaluator]: \u001b[0mInference done 19/1579. 0.0447 s / img. ETA=0:13:59\n",
      "\u001b[32m[09/09 10:55:36 d2.evaluation.evaluator]: \u001b[0mInference done 28/1579. 0.0450 s / img. ETA=0:14:33\n",
      "\u001b[32m[09/09 10:55:45 d2.evaluation.evaluator]: \u001b[0mInference done 29/1579. 0.0450 s / img. ETA=0:24:16\n",
      "\u001b[32m[09/09 10:55:50 d2.evaluation.evaluator]: \u001b[0mInference done 45/1579. 0.0444 s / img. ETA=0:17:36\n",
      "\u001b[32m[09/09 10:55:56 d2.evaluation.evaluator]: \u001b[0mInference done 63/1579. 0.0441 s / img. ETA=0:14:17\n",
      "\u001b[32m[09/09 10:56:01 d2.evaluation.evaluator]: \u001b[0mInference done 73/1579. 0.0444 s / img. ETA=0:14:00\n",
      "\u001b[32m[09/09 10:56:06 d2.evaluation.evaluator]: \u001b[0mInference done 79/1579. 0.0446 s / img. ETA=0:14:31\n",
      "\u001b[32m[09/09 10:56:12 d2.evaluation.evaluator]: \u001b[0mInference done 89/1579. 0.0447 s / img. ETA=0:14:22\n",
      "\u001b[32m[09/09 10:56:17 d2.evaluation.evaluator]: \u001b[0mInference done 100/1579. 0.0448 s / img. ETA=0:14:07\n",
      "\u001b[32m[09/09 10:56:23 d2.evaluation.evaluator]: \u001b[0mInference done 109/1579. 0.0448 s / img. ETA=0:14:03\n",
      "\u001b[32m[09/09 10:56:29 d2.evaluation.evaluator]: \u001b[0mInference done 121/1579. 0.0446 s / img. ETA=0:13:45\n",
      "\u001b[32m[09/09 10:56:34 d2.evaluation.evaluator]: \u001b[0mInference done 133/1579. 0.0444 s / img. ETA=0:13:21\n",
      "\u001b[32m[09/09 10:56:39 d2.evaluation.evaluator]: \u001b[0mInference done 142/1579. 0.0446 s / img. ETA=0:13:19\n",
      "\u001b[32m[09/09 10:56:44 d2.evaluation.evaluator]: \u001b[0mInference done 148/1579. 0.0447 s / img. ETA=0:13:35\n",
      "\u001b[32m[09/09 10:56:50 d2.evaluation.evaluator]: \u001b[0mInference done 162/1579. 0.0446 s / img. ETA=0:13:03\n",
      "\u001b[32m[09/09 10:56:55 d2.evaluation.evaluator]: \u001b[0mInference done 173/1579. 0.0444 s / img. ETA=0:12:50\n",
      "\u001b[32m[09/09 10:57:00 d2.evaluation.evaluator]: \u001b[0mInference done 183/1579. 0.0443 s / img. ETA=0:12:44\n",
      "\u001b[32m[09/09 10:57:06 d2.evaluation.evaluator]: \u001b[0mInference done 194/1579. 0.0442 s / img. ETA=0:12:32\n",
      "\u001b[32m[09/09 10:57:11 d2.evaluation.evaluator]: \u001b[0mInference done 203/1579. 0.0443 s / img. ETA=0:12:32\n",
      "\u001b[32m[09/09 10:57:16 d2.evaluation.evaluator]: \u001b[0mInference done 211/1579. 0.0444 s / img. ETA=0:12:32\n",
      "\u001b[32m[09/09 10:57:21 d2.evaluation.evaluator]: \u001b[0mInference done 220/1579. 0.0444 s / img. ETA=0:12:29\n",
      "\u001b[32m[09/09 10:57:27 d2.evaluation.evaluator]: \u001b[0mInference done 228/1579. 0.0444 s / img. ETA=0:12:30\n",
      "\u001b[32m[09/09 10:57:32 d2.evaluation.evaluator]: \u001b[0mInference done 237/1579. 0.0444 s / img. ETA=0:12:27\n",
      "\u001b[32m[09/09 10:57:37 d2.evaluation.evaluator]: \u001b[0mInference done 247/1579. 0.0444 s / img. ETA=0:12:18\n",
      "\u001b[32m[09/09 10:57:43 d2.evaluation.evaluator]: \u001b[0mInference done 255/1579. 0.0445 s / img. ETA=0:12:20\n",
      "\u001b[32m[09/09 10:57:48 d2.evaluation.evaluator]: \u001b[0mInference done 265/1579. 0.0445 s / img. ETA=0:12:13\n",
      "\u001b[32m[09/09 10:57:54 d2.evaluation.evaluator]: \u001b[0mInference done 275/1579. 0.0444 s / img. ETA=0:12:08\n",
      "\u001b[32m[09/09 10:57:59 d2.evaluation.evaluator]: \u001b[0mInference done 287/1579. 0.0445 s / img. ETA=0:11:56\n",
      "\u001b[32m[09/09 10:58:05 d2.evaluation.evaluator]: \u001b[0mInference done 296/1579. 0.0445 s / img. ETA=0:11:52\n",
      "\u001b[32m[09/09 10:58:10 d2.evaluation.evaluator]: \u001b[0mInference done 309/1579. 0.0444 s / img. ETA=0:11:36\n",
      "\u001b[32m[09/09 10:58:15 d2.evaluation.evaluator]: \u001b[0mInference done 319/1579. 0.0444 s / img. ETA=0:11:30\n",
      "\u001b[32m[09/09 10:58:21 d2.evaluation.evaluator]: \u001b[0mInference done 329/1579. 0.0444 s / img. ETA=0:11:26\n",
      "\u001b[32m[09/09 10:58:27 d2.evaluation.evaluator]: \u001b[0mInference done 338/1579. 0.0443 s / img. ETA=0:11:25\n",
      "\u001b[32m[09/09 10:58:33 d2.evaluation.evaluator]: \u001b[0mInference done 347/1579. 0.0444 s / img. ETA=0:11:23\n",
      "\u001b[32m[09/09 10:58:40 d2.evaluation.evaluator]: \u001b[0mInference done 356/1579. 0.0443 s / img. ETA=0:11:26\n",
      "\u001b[32m[09/09 10:58:45 d2.evaluation.evaluator]: \u001b[0mInference done 366/1579. 0.0444 s / img. ETA=0:11:19\n",
      "\u001b[32m[09/09 10:58:50 d2.evaluation.evaluator]: \u001b[0mInference done 374/1579. 0.0444 s / img. ETA=0:11:17\n",
      "\u001b[32m[09/09 10:58:56 d2.evaluation.evaluator]: \u001b[0mInference done 384/1579. 0.0444 s / img. ETA=0:11:10\n",
      "\u001b[32m[09/09 10:59:01 d2.evaluation.evaluator]: \u001b[0mInference done 395/1579. 0.0443 s / img. ETA=0:11:01\n",
      "\u001b[32m[09/09 10:59:06 d2.evaluation.evaluator]: \u001b[0mInference done 405/1579. 0.0443 s / img. ETA=0:10:55\n",
      "\u001b[32m[09/09 10:59:11 d2.evaluation.evaluator]: \u001b[0mInference done 413/1579. 0.0444 s / img. ETA=0:10:52\n",
      "\u001b[32m[09/09 10:59:16 d2.evaluation.evaluator]: \u001b[0mInference done 423/1579. 0.0443 s / img. ETA=0:10:45\n",
      "\u001b[32m[09/09 10:59:21 d2.evaluation.evaluator]: \u001b[0mInference done 433/1579. 0.0443 s / img. ETA=0:10:38\n",
      "\u001b[32m[09/09 10:59:27 d2.evaluation.evaluator]: \u001b[0mInference done 439/1579. 0.0443 s / img. ETA=0:10:40\n",
      "\u001b[32m[09/09 10:59:32 d2.evaluation.evaluator]: \u001b[0mInference done 448/1579. 0.0442 s / img. ETA=0:10:35\n",
      "\u001b[32m[09/09 10:59:37 d2.evaluation.evaluator]: \u001b[0mInference done 460/1579. 0.0442 s / img. ETA=0:10:25\n",
      "\u001b[32m[09/09 10:59:43 d2.evaluation.evaluator]: \u001b[0mInference done 469/1579. 0.0443 s / img. ETA=0:10:21\n",
      "\u001b[32m[09/09 10:59:48 d2.evaluation.evaluator]: \u001b[0mInference done 477/1579. 0.0443 s / img. ETA=0:10:18\n",
      "\u001b[32m[09/09 10:59:53 d2.evaluation.evaluator]: \u001b[0mInference done 489/1579. 0.0444 s / img. ETA=0:10:08\n",
      "\u001b[32m[09/09 10:59:59 d2.evaluation.evaluator]: \u001b[0mInference done 497/1579. 0.0443 s / img. ETA=0:10:06\n",
      "\u001b[32m[09/09 11:00:04 d2.evaluation.evaluator]: \u001b[0mInference done 510/1579. 0.0444 s / img. ETA=0:09:54\n",
      "\u001b[32m[09/09 11:00:09 d2.evaluation.evaluator]: \u001b[0mInference done 523/1579. 0.0444 s / img. ETA=0:09:43\n",
      "\u001b[32m[09/09 11:00:14 d2.evaluation.evaluator]: \u001b[0mInference done 534/1579. 0.0444 s / img. ETA=0:09:35\n",
      "\u001b[32m[09/09 11:00:20 d2.evaluation.evaluator]: \u001b[0mInference done 545/1579. 0.0444 s / img. ETA=0:09:28\n",
      "\u001b[32m[09/09 11:00:25 d2.evaluation.evaluator]: \u001b[0mInference done 550/1579. 0.0445 s / img. ETA=0:09:30\n",
      "\u001b[32m[09/09 11:00:30 d2.evaluation.evaluator]: \u001b[0mInference done 558/1579. 0.0445 s / img. ETA=0:09:27\n",
      "\u001b[32m[09/09 11:00:35 d2.evaluation.evaluator]: \u001b[0mInference done 569/1579. 0.0445 s / img. ETA=0:09:19\n",
      "\u001b[32m[09/09 11:00:41 d2.evaluation.evaluator]: \u001b[0mInference done 580/1579. 0.0445 s / img. ETA=0:09:12\n",
      "\u001b[32m[09/09 11:00:46 d2.evaluation.evaluator]: \u001b[0mInference done 591/1579. 0.0445 s / img. ETA=0:09:04\n",
      "\u001b[32m[09/09 11:00:51 d2.evaluation.evaluator]: \u001b[0mInference done 600/1579. 0.0444 s / img. ETA=0:08:59\n",
      "\u001b[32m[09/09 11:00:56 d2.evaluation.evaluator]: \u001b[0mInference done 610/1579. 0.0444 s / img. ETA=0:08:53\n",
      "\u001b[32m[09/09 11:01:01 d2.evaluation.evaluator]: \u001b[0mInference done 615/1579. 0.0444 s / img. ETA=0:08:54\n",
      "\u001b[32m[09/09 11:01:10 d2.evaluation.evaluator]: \u001b[0mInference done 626/1579. 0.0444 s / img. ETA=0:08:52\n",
      "\u001b[32m[09/09 11:01:15 d2.evaluation.evaluator]: \u001b[0mInference done 633/1579. 0.0445 s / img. ETA=0:08:50\n",
      "\u001b[32m[09/09 11:01:20 d2.evaluation.evaluator]: \u001b[0mInference done 640/1579. 0.0445 s / img. ETA=0:08:48\n",
      "\u001b[32m[09/09 11:01:26 d2.evaluation.evaluator]: \u001b[0mInference done 650/1579. 0.0445 s / img. ETA=0:08:42\n",
      "\u001b[32m[09/09 11:01:31 d2.evaluation.evaluator]: \u001b[0mInference done 658/1579. 0.0445 s / img. ETA=0:08:39\n",
      "\u001b[32m[09/09 11:01:36 d2.evaluation.evaluator]: \u001b[0mInference done 667/1579. 0.0445 s / img. ETA=0:08:34\n",
      "\u001b[32m[09/09 11:01:43 d2.evaluation.evaluator]: \u001b[0mInference done 676/1579. 0.0445 s / img. ETA=0:08:31\n",
      "\u001b[32m[09/09 11:01:49 d2.evaluation.evaluator]: \u001b[0mInference done 689/1579. 0.0444 s / img. ETA=0:08:22\n",
      "\u001b[32m[09/09 11:01:55 d2.evaluation.evaluator]: \u001b[0mInference done 702/1579. 0.0444 s / img. ETA=0:08:12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[09/09 11:02:00 d2.evaluation.evaluator]: \u001b[0mInference done 714/1579. 0.0444 s / img. ETA=0:08:04\n",
      "\u001b[32m[09/09 11:02:05 d2.evaluation.evaluator]: \u001b[0mInference done 723/1579. 0.0443 s / img. ETA=0:07:59\n",
      "\u001b[32m[09/09 11:02:10 d2.evaluation.evaluator]: \u001b[0mInference done 733/1579. 0.0443 s / img. ETA=0:07:53\n",
      "\u001b[32m[09/09 11:02:16 d2.evaluation.evaluator]: \u001b[0mInference done 738/1579. 0.0443 s / img. ETA=0:07:54\n",
      "\u001b[32m[09/09 11:02:21 d2.evaluation.evaluator]: \u001b[0mInference done 752/1579. 0.0444 s / img. ETA=0:07:43\n",
      "\u001b[32m[09/09 11:02:27 d2.evaluation.evaluator]: \u001b[0mInference done 769/1579. 0.0444 s / img. ETA=0:07:29\n",
      "\u001b[32m[09/09 11:02:33 d2.evaluation.evaluator]: \u001b[0mInference done 771/1579. 0.0444 s / img. ETA=0:07:33\n",
      "\u001b[32m[09/09 11:02:39 d2.evaluation.evaluator]: \u001b[0mInference done 793/1579. 0.0443 s / img. ETA=0:07:15\n",
      "\u001b[32m[09/09 11:02:44 d2.evaluation.evaluator]: \u001b[0mInference done 813/1579. 0.0443 s / img. ETA=0:06:58\n",
      "\u001b[32m[09/09 11:02:49 d2.evaluation.evaluator]: \u001b[0mInference done 836/1579. 0.0444 s / img. ETA=0:06:39\n",
      "\u001b[32m[09/09 11:02:54 d2.evaluation.evaluator]: \u001b[0mInference done 838/1579. 0.0444 s / img. ETA=0:06:41\n",
      "\u001b[32m[09/09 11:02:59 d2.evaluation.evaluator]: \u001b[0mInference done 852/1579. 0.0444 s / img. ETA=0:06:31\n",
      "\u001b[32m[09/09 11:03:04 d2.evaluation.evaluator]: \u001b[0mInference done 879/1579. 0.0444 s / img. ETA=0:06:09\n",
      "\u001b[32m[09/09 11:03:10 d2.evaluation.evaluator]: \u001b[0mInference done 904/1579. 0.0444 s / img. ETA=0:05:50\n",
      "\u001b[32m[09/09 11:03:18 d2.evaluation.evaluator]: \u001b[0mInference done 925/1579. 0.0444 s / img. ETA=0:05:37\n",
      "\u001b[32m[09/09 11:03:23 d2.evaluation.evaluator]: \u001b[0mInference done 941/1579. 0.0444 s / img. ETA=0:05:27\n",
      "\u001b[32m[09/09 11:03:28 d2.evaluation.evaluator]: \u001b[0mInference done 962/1579. 0.0443 s / img. ETA=0:05:12\n",
      "\u001b[32m[09/09 11:03:33 d2.evaluation.evaluator]: \u001b[0mInference done 987/1579. 0.0443 s / img. ETA=0:04:55\n",
      "\u001b[32m[09/09 11:03:38 d2.evaluation.evaluator]: \u001b[0mInference done 1005/1579. 0.0443 s / img. ETA=0:04:44\n",
      "\u001b[32m[09/09 11:03:44 d2.evaluation.evaluator]: \u001b[0mInference done 1025/1579. 0.0443 s / img. ETA=0:04:31\n",
      "\u001b[32m[09/09 11:03:49 d2.evaluation.evaluator]: \u001b[0mInference done 1044/1579. 0.0442 s / img. ETA=0:04:20\n",
      "\u001b[32m[09/09 11:03:54 d2.evaluation.evaluator]: \u001b[0mInference done 1059/1579. 0.0442 s / img. ETA=0:04:12\n",
      "\u001b[32m[09/09 11:03:59 d2.evaluation.evaluator]: \u001b[0mInference done 1069/1579. 0.0442 s / img. ETA=0:04:07\n",
      "\u001b[32m[09/09 11:04:04 d2.evaluation.evaluator]: \u001b[0mInference done 1084/1579. 0.0442 s / img. ETA=0:03:59\n",
      "\u001b[32m[09/09 11:04:09 d2.evaluation.evaluator]: \u001b[0mInference done 1096/1579. 0.0442 s / img. ETA=0:03:53\n",
      "\u001b[32m[09/09 11:04:14 d2.evaluation.evaluator]: \u001b[0mInference done 1122/1579. 0.0442 s / img. ETA=0:03:37\n",
      "\u001b[32m[09/09 11:04:19 d2.evaluation.evaluator]: \u001b[0mInference done 1147/1579. 0.0442 s / img. ETA=0:03:22\n",
      "\u001b[32m[09/09 11:04:26 d2.evaluation.evaluator]: \u001b[0mInference done 1160/1579. 0.0441 s / img. ETA=0:03:17\n",
      "\u001b[32m[09/09 11:04:31 d2.evaluation.evaluator]: \u001b[0mInference done 1183/1579. 0.0441 s / img. ETA=0:03:04\n",
      "\u001b[32m[09/09 11:04:36 d2.evaluation.evaluator]: \u001b[0mInference done 1211/1579. 0.0440 s / img. ETA=0:02:48\n",
      "\u001b[32m[09/09 11:04:41 d2.evaluation.evaluator]: \u001b[0mInference done 1239/1579. 0.0440 s / img. ETA=0:02:33\n",
      "\u001b[32m[09/09 11:04:47 d2.evaluation.evaluator]: \u001b[0mInference done 1266/1579. 0.0440 s / img. ETA=0:02:19\n",
      "\u001b[32m[09/09 11:04:52 d2.evaluation.evaluator]: \u001b[0mInference done 1280/1579. 0.0440 s / img. ETA=0:02:13\n",
      "\u001b[32m[09/09 11:04:57 d2.evaluation.evaluator]: \u001b[0mInference done 1304/1579. 0.0440 s / img. ETA=0:02:01\n",
      "\u001b[32m[09/09 11:05:04 d2.evaluation.evaluator]: \u001b[0mInference done 1328/1579. 0.0439 s / img. ETA=0:01:50\n",
      "\u001b[32m[09/09 11:05:09 d2.evaluation.evaluator]: \u001b[0mInference done 1349/1579. 0.0439 s / img. ETA=0:01:40\n",
      "\u001b[32m[09/09 11:05:14 d2.evaluation.evaluator]: \u001b[0mInference done 1373/1579. 0.0439 s / img. ETA=0:01:29\n",
      "\u001b[32m[09/09 11:05:19 d2.evaluation.evaluator]: \u001b[0mInference done 1393/1579. 0.0438 s / img. ETA=0:01:19\n",
      "\u001b[32m[09/09 11:05:33 d2.evaluation.evaluator]: \u001b[0mInference done 1401/1579. 0.0438 s / img. ETA=0:01:17\n",
      "\u001b[32m[09/09 11:05:38 d2.evaluation.evaluator]: \u001b[0mInference done 1421/1579. 0.0438 s / img. ETA=0:01:08\n",
      "\u001b[32m[09/09 11:05:43 d2.evaluation.evaluator]: \u001b[0mInference done 1437/1579. 0.0439 s / img. ETA=0:01:01\n",
      "\u001b[32m[09/09 11:05:49 d2.evaluation.evaluator]: \u001b[0mInference done 1453/1579. 0.0439 s / img. ETA=0:00:54\n",
      "\u001b[32m[09/09 11:05:55 d2.evaluation.evaluator]: \u001b[0mInference done 1469/1579. 0.0439 s / img. ETA=0:00:47\n",
      "\u001b[32m[09/09 11:06:00 d2.evaluation.evaluator]: \u001b[0mInference done 1475/1579. 0.0439 s / img. ETA=0:00:45\n",
      "\u001b[32m[09/09 11:06:05 d2.evaluation.evaluator]: \u001b[0mInference done 1487/1579. 0.0439 s / img. ETA=0:00:39\n",
      "\u001b[32m[09/09 11:06:10 d2.evaluation.evaluator]: \u001b[0mInference done 1497/1579. 0.0439 s / img. ETA=0:00:35\n",
      "\u001b[32m[09/09 11:06:17 d2.evaluation.evaluator]: \u001b[0mInference done 1513/1579. 0.0439 s / img. ETA=0:00:28\n",
      "\u001b[32m[09/09 11:06:22 d2.evaluation.evaluator]: \u001b[0mInference done 1525/1579. 0.0439 s / img. ETA=0:00:23\n",
      "\u001b[32m[09/09 11:06:27 d2.evaluation.evaluator]: \u001b[0mInference done 1550/1579. 0.0438 s / img. ETA=0:00:12\n",
      "\u001b[32m[09/09 11:06:36 d2.evaluation.evaluator]: \u001b[0mInference done 1570/1579. 0.0439 s / img. ETA=0:00:03\n",
      "\u001b[32m[09/09 11:06:38 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:11:14.650753 (0.428622 s / img per device, on 1 devices)\n",
      "\u001b[32m[09/09 11:06:38 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:09 (0.043854 s / img per device, on 1 devices)\n",
      "\u001b[32m[09/09 11:06:39 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[09/09 11:06:39 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output/adv_0/coco_instances_results.json\n",
      "\u001b[32m[09/09 11:06:39 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.12s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=1.54s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.49s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.129\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.209\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.142\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.005\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.101\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.238\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.196\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.355\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.358\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.077\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.341\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.434\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.506\n",
      " Average Recall     (AR) @[ IoU=0.70      | area=   all | maxDets=100 ] = 0.437\n",
      " Average Recall     (AR) @[ IoU=0.85      | area=   all | maxDets=100 ] = 0.264\n",
      "\u001b[32m[09/09 11:06:41 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 12.872 | 20.919 | 14.240 | 0.463 | 10.139 | 23.839 |\n",
      "\u001b[32m[09/09 11:06:41 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category   | AP     | category   | AP     |\n",
      "|:-----------|:-------|:-----------|:-------|\n",
      "| box        | 12.928 | logo       | 12.816 |\n",
      "\u001b[32m[09/09 11:06:41 d2.engine.defaults]: \u001b[0mEvaluation results for benign_adv_test in csv format:\n",
      "\u001b[32m[09/09 11:06:41 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[09/09 11:06:41 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[09/09 11:06:41 d2.evaluation.testing]: \u001b[0mcopypaste: 12.8720,20.9194,14.2396,0.4628,10.1389,23.8387\n",
      "loading annotations into memory...\n",
      "Done (t=0.03s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.29s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.06s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Command Line Args: Namespace(config_file='configs/faster_rcnn_adv_eval_test.yaml', dist_url='tcp://127.0.0.1:49923', eval_only=True, machine_rank=0, num_gpus=1, num_machines=1, opts=['MODEL.WEIGHTS', 'output/adv_1/model_final.pth', 'OUTPUT_DIR', 'output/adv_1'], resume=False)\n",
      "\u001b[32m[09/09 11:06:45 detectron2]: \u001b[0mRank of current process: 0. World size: 1\n",
      "\u001b[32m[09/09 11:06:47 detectron2]: \u001b[0mEnvironment info:\n",
      "----------------------  -------------------------------------------------------------------------------------------\n",
      "sys.platform            linux\n",
      "Python                  3.7.7 (default, Mar 23 2020, 22:36:06) [GCC 7.3.0]\n",
      "numpy                   1.18.1\n",
      "detectron2              0.1.3 @/home/l/liny/anaconda3/envs/mypy37/lib/python3.7/site-packages/detectron2\n",
      "Compiler                GCC 5.4\n",
      "CUDA compiler           CUDA 9.2\n",
      "detectron2 arch flags   sm_70\n",
      "DETECTRON2_ENV_MODULE   <not set>\n",
      "PyTorch                 1.5.0 @/home/l/liny/anaconda3/envs/mypy37/lib/python3.7/site-packages/torch\n",
      "PyTorch debug build     False\n",
      "GPU available           True\n",
      "GPU 0                   Tesla V100-PCIE-16GB\n",
      "CUDA_HOME               /usr/local/cuda-9.2\n",
      "Pillow                  7.0.0\n",
      "torchvision             0.6.0a0+82fd1c8 @/home/l/liny/anaconda3/envs/mypy37/lib/python3.7/site-packages/torchvision\n",
      "torchvision arch flags  sm_35, sm_50, sm_60, sm_70\n",
      "fvcore                  0.1.1.post20200618\n",
      "cv2                     4.3.0\n",
      "----------------------  -------------------------------------------------------------------------------------------\n",
      "PyTorch built with:\n",
      "  - GCC 7.3\n",
      "  - C++ Version: 201402\n",
      "  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v0.21.1 (Git Hash 7d2fd500bc78936d1d648ca713b901012f470dbc)\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
      "  - NNPACK is enabled\n",
      "  - CPU capability usage: AVX2\n",
      "  - CUDA Runtime 9.2\n",
      "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_37,code=compute_37\n",
      "  - CuDNN 7.6.3\n",
      "  - Magma 2.5.2\n",
      "  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_INTERNAL_THREADPOOL_IMPL -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, \n",
      "\n",
      "\u001b[32m[09/09 11:06:47 detectron2]: \u001b[0mCommand line arguments: Namespace(config_file='configs/faster_rcnn_adv_eval_test.yaml', dist_url='tcp://127.0.0.1:49923', eval_only=True, machine_rank=0, num_gpus=1, num_machines=1, opts=['MODEL.WEIGHTS', 'output/adv_1/model_final.pth', 'OUTPUT_DIR', 'output/adv_1'], resume=False)\n",
      "\u001b[32m[09/09 11:06:47 detectron2]: \u001b[0mContents of args.config_file=configs/faster_rcnn_adv_eval_test.yaml:\n",
      "_BASE_: \"./bases/Base-RCNN-FPN.yaml\"\n",
      "MODEL:\n",
      "  # COCO ResNet50 weights\n",
      "  WEIGHTS: \"./output/rcnn_bet365/model_final.pth\"\n",
      "  MASK_ON: False # Not doing segmentation\n",
      "  RESNETS:\n",
      "    DEPTH: 50 # ResNet50\n",
      "  ROI_HEADS:\n",
      "    NUM_CLASSES: 2 # Change to suit own task\n",
      "    # Can reduce this for lower memory/faster training; Default 512\n",
      "    BATCH_SIZE_PER_IMAGE: 512\n",
      "  BACKBONE:\n",
      "    FREEZE_AT: 2 # Default 2\n",
      "DATASETS:\n",
      "  TRAIN: (\"benign_adv\",)\n",
      "  TEST: (\"benign_adv_test\",)\n",
      "DATALOADER:\n",
      "  NUM_WORKERS: 0\n",
      "SOLVER:\n",
      "  IMS_PER_BATCH: 8 # Batch size; Default 16\n",
      "  BASE_LR: 0.00005\n",
      "  # (2/3, 8/9)\n",
      "  STEPS: (2000, 5000) # The iteration number to decrease learning rate by GAMMA.\n",
      "  MAX_ITER: 7000 # Number of training iterations\n",
      "  CHECKPOINT_PERIOD: 1000 # Saves checkpoint every number of steps\n",
      "INPUT:\n",
      "  MIN_SIZE_TRAIN: (640, 672, 704, 736, 768, 800) # Image input sizes\n",
      "TEST:\n",
      "  # The period (in terms of steps) to evaluate the model during training.\n",
      "  # Set to 0 to disable.\n",
      "  EVAL_PERIOD: 1000\n",
      "OUTPUT_DIR: \"./output/adv\" # Specify output directory\n",
      "\n",
      "\u001b[32m[09/09 11:06:47 detectron2]: \u001b[0mRunning with full config:\n",
      "CUDNN_BENCHMARK: False\n",
      "DATALOADER:\n",
      "  ASPECT_RATIO_GROUPING: True\n",
      "  FILTER_EMPTY_ANNOTATIONS: True\n",
      "  NUM_WORKERS: 0\n",
      "  REPEAT_THRESHOLD: 0.0\n",
      "  SAMPLER_TRAIN: TrainingSampler\n",
      "DATASETS:\n",
      "  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000\n",
      "  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000\n",
      "  PROPOSAL_FILES_TEST: ()\n",
      "  PROPOSAL_FILES_TRAIN: ()\n",
      "  TEST: ('benign_adv_test',)\n",
      "  TRAIN: ('benign_adv',)\n",
      "GLOBAL:\n",
      "  HACK: 1.0\n",
      "INPUT:\n",
      "  CROP:\n",
      "    ENABLED: False\n",
      "    SIZE: [0.9, 0.9]\n",
      "    TYPE: relative_range\n",
      "  FORMAT: BGR\n",
      "  MASK_FORMAT: polygon\n",
      "  MAX_SIZE_TEST: 1333\n",
      "  MAX_SIZE_TRAIN: 1333\n",
      "  MIN_SIZE_TEST: 800\n",
      "  MIN_SIZE_TRAIN: (640, 672, 704, 736, 768, 800)\n",
      "  MIN_SIZE_TRAIN_SAMPLING: choice\n",
      "MODEL:\n",
      "  ANCHOR_GENERATOR:\n",
      "    ANGLES: [[-90, 0, 90]]\n",
      "    ASPECT_RATIOS: [[0.5, 1.0, 2.0]]\n",
      "    NAME: DefaultAnchorGenerator\n",
      "    OFFSET: 0.0\n",
      "    SIZES: [[32], [64], [128], [256], [512]]\n",
      "  BACKBONE:\n",
      "    FREEZE_AT: 2\n",
      "    NAME: build_resnet_fpn_backbone\n",
      "  DEVICE: cuda\n",
      "  FPN:\n",
      "    FUSE_TYPE: sum\n",
      "    IN_FEATURES: ['res2', 'res3', 'res4', 'res5']\n",
      "    NORM: \n",
      "    OUT_CHANNELS: 256\n",
      "  KEYPOINT_ON: False\n",
      "  LOAD_PROPOSALS: False\n",
      "  MASK_ON: False\n",
      "  META_ARCHITECTURE: GeneralizedRCNN\n",
      "  PANOPTIC_FPN:\n",
      "    COMBINE:\n",
      "      ENABLED: True\n",
      "      INSTANCES_CONFIDENCE_THRESH: 0.5\n",
      "      OVERLAP_THRESH: 0.5\n",
      "      STUFF_AREA_LIMIT: 4096\n",
      "    INSTANCE_LOSS_WEIGHT: 1.0\n",
      "  PIXEL_MEAN: [103.53, 116.28, 123.675]\n",
      "  PIXEL_STD: [1.0, 1.0, 1.0]\n",
      "  PROPOSAL_GENERATOR:\n",
      "    MIN_SIZE: 0\n",
      "    NAME: RPN\n",
      "  RESNETS:\n",
      "    DEFORM_MODULATED: False\n",
      "    DEFORM_NUM_GROUPS: 1\n",
      "    DEFORM_ON_PER_STAGE: [False, False, False, False]\n",
      "    DEPTH: 50\n",
      "    NORM: FrozenBN\n",
      "    NUM_GROUPS: 1\n",
      "    OUT_FEATURES: ['res2', 'res3', 'res4', 'res5']\n",
      "    RES2_OUT_CHANNELS: 256\n",
      "    RES5_DILATION: 1\n",
      "    STEM_OUT_CHANNELS: 64\n",
      "    STRIDE_IN_1X1: True\n",
      "    WIDTH_PER_GROUP: 64\n",
      "  RETINANET:\n",
      "    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)\n",
      "    FOCAL_LOSS_ALPHA: 0.25\n",
      "    FOCAL_LOSS_GAMMA: 2.0\n",
      "    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']\n",
      "    IOU_LABELS: [0, -1, 1]\n",
      "    IOU_THRESHOLDS: [0.4, 0.5]\n",
      "    NMS_THRESH_TEST: 0.5\n",
      "    NUM_CLASSES: 80\n",
      "    NUM_CONVS: 4\n",
      "    PRIOR_PROB: 0.01\n",
      "    SCORE_THRESH_TEST: 0.05\n",
      "    SMOOTH_L1_LOSS_BETA: 0.1\n",
      "    TOPK_CANDIDATES_TEST: 1000\n",
      "  ROI_BOX_CASCADE_HEAD:\n",
      "    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))\n",
      "    IOUS: (0.5, 0.6, 0.7)\n",
      "  ROI_BOX_HEAD:\n",
      "    BBOX_REG_LOSS_TYPE: smooth_l1\n",
      "    BBOX_REG_LOSS_WEIGHT: 1.0\n",
      "    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)\n",
      "    CLS_AGNOSTIC_BBOX_REG: False\n",
      "    CONV_DIM: 256\n",
      "    FC_DIM: 1024\n",
      "    NAME: FastRCNNConvFCHead\n",
      "    NORM: \n",
      "    NUM_CONV: 0\n",
      "    NUM_FC: 2\n",
      "    POOLER_RESOLUTION: 7\n",
      "    POOLER_SAMPLING_RATIO: 0\n",
      "    POOLER_TYPE: ROIAlignV2\n",
      "    SMOOTH_L1_BETA: 0.0\n",
      "    TRAIN_ON_PRED_BOXES: False\n",
      "  ROI_HEADS:\n",
      "    BATCH_SIZE_PER_IMAGE: 512\n",
      "    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']\n",
      "    IOU_LABELS: [0, 1]\n",
      "    IOU_THRESHOLDS: [0.5]\n",
      "    NAME: StandardROIHeads\n",
      "    NMS_THRESH_TEST: 0.5\n",
      "    NUM_CLASSES: 2\n",
      "    POSITIVE_FRACTION: 0.25\n",
      "    PROPOSAL_APPEND_GT: True\n",
      "    SCORE_THRESH_TEST: 0.05\n",
      "  ROI_KEYPOINT_HEAD:\n",
      "    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)\n",
      "    LOSS_WEIGHT: 1.0\n",
      "    MIN_KEYPOINTS_PER_IMAGE: 1\n",
      "    NAME: KRCNNConvDeconvUpsampleHead\n",
      "    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True\n",
      "    NUM_KEYPOINTS: 17\n",
      "    POOLER_RESOLUTION: 14\n",
      "    POOLER_SAMPLING_RATIO: 0\n",
      "    POOLER_TYPE: ROIAlignV2\n",
      "  ROI_MASK_HEAD:\n",
      "    CLS_AGNOSTIC_MASK: False\n",
      "    CONV_DIM: 256\n",
      "    NAME: MaskRCNNConvUpsampleHead\n",
      "    NORM: \n",
      "    NUM_CONV: 4\n",
      "    POOLER_RESOLUTION: 14\n",
      "    POOLER_SAMPLING_RATIO: 0\n",
      "    POOLER_TYPE: ROIAlignV2\n",
      "  RPN:\n",
      "    BATCH_SIZE_PER_IMAGE: 256\n",
      "    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)\n",
      "    BOUNDARY_THRESH: -1\n",
      "    HEAD_NAME: StandardRPNHead\n",
      "    IN_FEATURES: ['p2', 'p3', 'p4', 'p5', 'p6']\n",
      "    IOU_LABELS: [0, -1, 1]\n",
      "    IOU_THRESHOLDS: [0.3, 0.7]\n",
      "    LOSS_WEIGHT: 1.0\n",
      "    NMS_THRESH: 0.7\n",
      "    POSITIVE_FRACTION: 0.5\n",
      "    POST_NMS_TOPK_TEST: 1000\n",
      "    POST_NMS_TOPK_TRAIN: 1000\n",
      "    PRE_NMS_TOPK_TEST: 1000\n",
      "    PRE_NMS_TOPK_TRAIN: 2000\n",
      "    SMOOTH_L1_BETA: 0.0\n",
      "  SEM_SEG_HEAD:\n",
      "    COMMON_STRIDE: 4\n",
      "    CONVS_DIM: 128\n",
      "    IGNORE_VALUE: 255\n",
      "    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']\n",
      "    LOSS_WEIGHT: 1.0\n",
      "    NAME: SemSegFPNHead\n",
      "    NORM: GN\n",
      "    NUM_CLASSES: 54\n",
      "  WEIGHTS: output/adv_1/model_final.pth\n",
      "OUTPUT_DIR: output/adv_1\n",
      "SEED: -1\n",
      "SOLVER:\n",
      "  BASE_LR: 5e-05\n",
      "  BIAS_LR_FACTOR: 1.0\n",
      "  CHECKPOINT_PERIOD: 1000\n",
      "  CLIP_GRADIENTS:\n",
      "    CLIP_TYPE: value\n",
      "    CLIP_VALUE: 1.0\n",
      "    ENABLED: False\n",
      "    NORM_TYPE: 2.0\n",
      "  GAMMA: 0.1\n",
      "  IMS_PER_BATCH: 8\n",
      "  LR_SCHEDULER_NAME: WarmupMultiStepLR\n",
      "  MAX_ITER: 7000\n",
      "  MOMENTUM: 0.9\n",
      "  NESTEROV: False\n",
      "  STEPS: (2000, 5000)\n",
      "  WARMUP_FACTOR: 0.001\n",
      "  WARMUP_ITERS: 1000\n",
      "  WARMUP_METHOD: linear\n",
      "  WEIGHT_DECAY: 0.0001\n",
      "  WEIGHT_DECAY_BIAS: 0.0001\n",
      "  WEIGHT_DECAY_NORM: 0.0\n",
      "TEST:\n",
      "  AUG:\n",
      "    ENABLED: False\n",
      "    FLIP: True\n",
      "    MAX_SIZE: 4000\n",
      "    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)\n",
      "  DETECTIONS_PER_IMAGE: 100\n",
      "  EVAL_PERIOD: 1000\n",
      "  EXPECTED_RESULTS: []\n",
      "  KEYPOINT_OKS_SIGMAS: []\n",
      "  PRECISE_BN:\n",
      "    ENABLED: False\n",
      "    NUM_ITER: 200\n",
      "VERSION: 2\n",
      "VIS_PERIOD: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[09/09 11:06:48 detectron2]: \u001b[0mFull config saved to output/adv_1/config.yaml\n",
      "\u001b[32m[09/09 11:06:48 d2.utils.env]: \u001b[0mUsing a generated random seed 49164121\n",
      "\u001b[32m[09/09 11:06:52 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=3, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=8, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[09/09 11:06:52 fvcore.common.checkpoint]: \u001b[0mLoading checkpoint from output/adv_1/model_final.pth\n",
      "Traceback (most recent call last):\n",
      "  File \"train_net.py\", line 151, in <module>\n",
      "    args=(args,),\n",
      "  File \"/home/l/liny/anaconda3/envs/mypy37/lib/python3.7/site-packages/detectron2/engine/launch.py\", line 57, in launch\n",
      "    main_func(*args)\n",
      "  File \"train_net.py\", line 115, in main\n",
      "    cfg.MODEL.WEIGHTS, resume=args.resume\n",
      "  File \"/home/l/liny/anaconda3/envs/mypy37/lib/python3.7/site-packages/fvcore/common/checkpoint.py\", line 189, in resume_or_load\n",
      "    return self.load(path, checkpointables=[])\n",
      "  File \"/home/l/liny/anaconda3/envs/mypy37/lib/python3.7/site-packages/fvcore/common/checkpoint.py\", line 115, in load\n",
      "    assert os.path.isfile(path), \"Checkpoint {} not found!\".format(path)\n",
      "AssertionError: Checkpoint output/adv_1/model_final.pth not found!\n",
      "loading annotations into memory...\n",
      "Done (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.04s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.06s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'output/adv_2/coco_instances_results.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-fd99a8da3721>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mresults_coco_path\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0moutput_this_epoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/coco_instances_results.json'\u001b[0m \u001b[0;31m# here the prediction is for the resized image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mcoco_gt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCOCO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgt_coco_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m     \u001b[0mcoco_dt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoco_gt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadRes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults_coco_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mcoco_eval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCOCOeval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoco_gt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoco_dt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'bbox'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mypy37/lib/python3.7/site-packages/pycocotools/coco.py\u001b[0m in \u001b[0;36mloadRes\u001b[0;34m(self, resFile)\u001b[0m\n\u001b[1;32m    315\u001b[0m         \u001b[0mtic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresFile\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mPYTHON_VERSION\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresFile\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0municode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 317\u001b[0;31m             \u001b[0manns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    318\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresFile\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m             \u001b[0manns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadNumpyAnnotations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'output/adv_2/coco_instances_results.json'"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(20):\n",
    "    if i == 0:\n",
    "        weight_last_epoch = 'output/rcnn_bet365/model_final.pth'\n",
    "    else:\n",
    "        weight_last_epoch = 'output/adv_%s/model_final.pth'%(str(i - 1))\n",
    "    output_this_epoch = 'output/adv_%s'%(str(i))\n",
    "    weight_this_epoch = output_this_epoch + '/model_final.pth'\n",
    "    \n",
    "    '''generate training, testing adv examples'''\n",
    "    !python run_DAG.py --test False --cfg-path configs/faster_rcnn_bet365.yaml \\\n",
    "                                               --weights-path {weight_last_epoch} \\\n",
    "                                               --results-save-path coco_instances_ignore_train.json \n",
    "\n",
    "    !python run_DAG.py --test True --cfg-path configs/faster_rcnn_bet365.yaml \\\n",
    "                                              --weights-path {weight_last_epoch} \\\n",
    "                                              --results-save-path coco_instances_ignore_test.json \n",
    "        \n",
    "    #mix normal with training\n",
    "    !python detectron2_1/mix_normal_adv.py --normal-path data/benign_data/coco_train.json \\\n",
    "                                           --adv-path data/benign_data/coco_perturbgt_train.json \\\n",
    "                                           --save-path data/benign_data/coco_adv_mix.json \n",
    "\n",
    "    #retrain \n",
    "    !python train_net.py --config-file configs/faster_rcnn_adv.yaml \\\n",
    "                                       OUTPUT_DIR {output_this_epoch} \\\n",
    "                                       MODEL.WEIGHTS {weight_last_epoch} \\\n",
    "    \n",
    "    # evaluate training acc\n",
    "    !python train_net.py --eval-only --config-file configs/faster_rcnn_adv_eval_train.yaml \\\n",
    "                                                   MODEL.WEIGHTS {weight_this_epoch} \\\n",
    "                                                   OUTPUT_DIR {output_this_epoch} # Path to trained checkpoint\n",
    "    \n",
    "    gt_coco_path = 'data/benign_data/coco_adv_mix.json' # here the ground-truth is for the original-sized image\n",
    "    results_coco_path =  output_this_epoch + '/coco_instances_results.json' # here the prediction is for the resized image\n",
    "    coco_gt = COCO(gt_coco_path)\n",
    "    coco_dt = coco_gt.loadRes(results_coco_path)\n",
    "    \n",
    "    coco_eval = COCOeval(coco_gt, coco_dt, 'bbox')\n",
    "    with open(output_this_epoch + '/all_trainacc.pkl', 'wb') as f:\n",
    "        pickle.dump(coco_eval, f)\n",
    "    \n",
    "    coco_eval = COCOeval(coco_gt, coco_dt, 'bbox')\n",
    "    coco_eval.params.catIds = [1]\n",
    "    with open(output_this_epoch + '/input_trainacc.pkl', 'wb') as f:\n",
    "        pickle.dump(coco_eval, f)\n",
    "        \n",
    "    coco_eval = COCOeval(coco_gt, coco_dt, 'bbox')\n",
    "    coco_eval.params.catIds = [2]\n",
    "    with open(output_this_epoch + '/logo_trainacc.pkl', 'wb') as f:\n",
    "        pickle.dump(coco_eval, f)\n",
    "        \n",
    "    # evaluate testing acc\n",
    "    !python train_net.py --eval-only --config-file configs/faster_rcnn_adv_eval_test.yaml \\\n",
    "                                     MODEL.WEIGHTS {weight_this_epoch} \\\n",
    "                                     OUTPUT_DIR {output_this_epoch} # Path to trained checkpoint\n",
    "    \n",
    "    gt_coco_path = 'data/benign_data/coco_perturbgt_test.json' \n",
    "    results_coco_path =  output_this_epoch + '/coco_instances_results.json' \n",
    "    coco_gt = COCO(gt_coco_path)\n",
    "    coco_dt = coco_gt.loadRes(results_coco_path)\n",
    "    \n",
    "    coco_eval = COCOeval(coco_gt, coco_dt, 'bbox')\n",
    "    with open(output_this_epoch + '/all_testacc.pkl', 'wb') as f:\n",
    "        pickle.dump(coco_eval, f)\n",
    "    \n",
    "    coco_eval = COCOeval(coco_gt, coco_dt, 'bbox')\n",
    "    coco_eval.params.catIds = [1]\n",
    "    with open(output_this_epoch + '/input_testacc.pkl', 'wb') as f:\n",
    "        pickle.dump(coco_eval, f)\n",
    "    \n",
    "    coco_eval = COCOeval(coco_gt, coco_dt, 'bbox')\n",
    "    coco_eval.params.catIds = [2]\n",
    "    with open(output_this_epoch + '/logo_testacc.pkl', 'wb') as f:\n",
    "        pickle.dump(coco_eval, f)\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./output/adv_1/logo_testacc.pkl', 'rb') as f:\n",
    "    logo_testacc = pickle.load(f)\n",
    "    \n",
    "with open('./output/adv_1/input_testacc.pkl', 'rb') as f:\n",
    "    input_testacc = pickle.load(f)\n",
    "    \n",
    "with open('./output/adv_1/all_testacc.pkl', 'rb') as f:\n",
    "    all_testacc = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./output/adv_1/logo_trainacc.pkl', 'rb') as f:\n",
    "    logo_trainacc = pickle.load(f)\n",
    "    \n",
    "with open('./output/adv_1/input_trainacc.pkl', 'rb') as f:\n",
    "    input_trainacc = pickle.load(f)\n",
    "    \n",
    "with open('./output/adv_1/all_trainacc.pkl', 'rb') as f:\n",
    "    all_trainacc = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.24s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.06s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.70      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.85      | area=   all | maxDets=100 ] = 0.000\n"
     ]
    }
   ],
   "source": [
    "logo_testacc.evaluate()\n",
    "logo_testacc.accumulate()\n",
    "logo_testacc.summarize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:mypy37]",
   "language": "python",
   "name": "conda-env-mypy37-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
