{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterative Adv Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For iter in Range(20):\n",
    "-       Step 1: Generate training adv examples to 1) overwrite shot_adv.png 2) create coco_perturb_train.json\n",
    "-       Step 2: Mix downsampled normal training data with perturbed training data (4:1) and create coco_adv_mix.json\n",
    "-       Step 3: Evaluate training Acc on all clean+adv examples (9 metrics)\n",
    "-       Step 4: Gerenate testing adv examples .... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycocotools.coco import COCO\n",
    "from pycocotools.cocoeval import COCOeval\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/l/liny/yizhe/code/detectron2-1\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing config file...\n",
      "Initializing attacker...\n",
      "Start the attack...\n",
      "0it [00:00, ?it/s][0/29073] Attacking data/benign_data/benign_database/fuzer.me/shot.png ...\n",
      "Done with attack. Total Iterations 96\n",
      "1it [00:12, 12.70s/it][1/29073] Attacking data/benign_data/benign_database/ufms.br/shot.png ...\n",
      "Done with attack. Total Iterations 149\n",
      "2it [00:23, 11.98s/it][2/29073] Attacking data/benign_data/benign_database/camsis.ru/shot.png ...\n",
      "Done with attack. Total Iterations 149\n",
      "3it [00:33, 11.65s/it][3/29073] Attacking data/benign_data/benign_database/northcarolina.edu/shot.png ...\n",
      "^C\n",
      "3it [00:36, 12.26s/it]\n",
      "Traceback (most recent call last):\n",
      "  File \"run_DAG.py\", line 55, in <module>\n",
      "    main(args)\n",
      "  File \"run_DAG.py\", line 20, in main\n",
      "    results_save_path=args.results_save_path, vis_save_dir=args.vis_save_dir\n",
      "  File \"/home/l/liny/yizhe/code/detectron2-1/detectron2_1/adv_train.py\", line 157, in run_DAG\n",
      "    perturbed_image, r_accum = self.attack_image(batch)\n",
      "  File \"/home/l/liny/yizhe/code/detectron2-1/detectron2_1/adv_train.py\", line 258, in attack_image\n",
      "    logits, _ = self._get_roi_heads_predictions(features, target_boxes)\n",
      "  File \"/home/l/liny/yizhe/code/detectron2-1/detectron2_1/adv_train.py\", line 499, in _get_roi_heads_predictions\n",
      "    box_features = roi_heads.box_pooler(features, [proposal_boxes])\n",
      "  File \"/home/l/liny/anaconda3/envs/mypy37/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 550, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/l/liny/anaconda3/envs/mypy37/lib/python3.7/site-packages/detectron2/modeling/poolers.py\", line 230, in forward\n",
      "    inds = nonzero_tuple(level_assignments == level)[0]\n",
      "  File \"/home/l/liny/anaconda3/envs/mypy37/lib/python3.7/site-packages/detectron2/layers/wrappers.py\", line 226, in nonzero_tuple\n",
      "    return x.nonzero().unbind(1)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(1, 20):\n",
    "    if i == 0:\n",
    "        weight_last_epoch = 'output/rcnn_bet365/model_final.pth'\n",
    "    else:\n",
    "        weight_last_epoch = 'output/adv_%s/model_final.pth'%(str(i - 1))\n",
    "    output_this_epoch = 'output/adv_%s'%(str(i))\n",
    "    weight_this_epoch = output_this_epoch + '/model_final.pth'\n",
    "    \n",
    "    if not (os.path.exists(weight_last_epoch)):\n",
    "        print('Weight for last epoch not exist!')\n",
    "        \n",
    "    if not os.path.exists()\n",
    "        \n",
    "    '''generate training, testing adv examples'''\n",
    "    !python run_DAG.py --test False --cfg-path configs/faster_rcnn_bet365.yaml \\\n",
    "                                               --weights-path {weight_last_epoch} \\\n",
    "                                               --results-save-path coco_instances_ignore_train.json \n",
    "\n",
    "    !python run_DAG.py --test True --cfg-path configs/faster_rcnn_bet365.yaml \\\n",
    "                                              --weights-path {weight_last_epoch} \\\n",
    "                                              --results-save-path coco_instances_ignore_test.json \n",
    "        \n",
    "    #mix normal with training\n",
    "    !python detectron2_1/mix_normal_adv.py --normal-path data/benign_data/coco_train.json \\\n",
    "                                           --adv-path data/benign_data/coco_perturbgt_train.json \\\n",
    "                                           --save-path data/benign_data/coco_adv_mix.json \n",
    "\n",
    "    #retrain \n",
    "    !python train_net.py --config-file configs/faster_rcnn_adv.yaml \\\n",
    "                                       OUTPUT_DIR {output_this_epoch} \\\n",
    "                                       MODEL.WEIGHTS {weight_last_epoch} \\\n",
    "    \n",
    "    # evaluate training acc\n",
    "    !python train_net.py --eval-only --config-file configs/faster_rcnn_adv_eval_train.yaml \\\n",
    "                                                   MODEL.WEIGHTS {weight_this_epoch} \\\n",
    "                                                   OUTPUT_DIR {output_this_epoch} # Path to trained checkpoint\n",
    "    \n",
    "    gt_coco_path = 'data/benign_data/coco_adv_mix.json' # here the ground-truth is for the original-sized image\n",
    "    results_coco_path =  output_this_epoch + '/coco_instances_results.json' # here the prediction is for the resized image\n",
    "    coco_gt = COCO(gt_coco_path)\n",
    "    coco_dt = coco_gt.loadRes(results_coco_path)\n",
    "    \n",
    "    coco_eval = COCOeval(coco_gt, coco_dt, 'bbox')\n",
    "    with open(output_this_epoch + '/all_trainacc.pkl', 'wb') as f:\n",
    "        pickle.dump(coco_eval, f)\n",
    "    \n",
    "    coco_eval = COCOeval(coco_gt, coco_dt, 'bbox')\n",
    "    coco_eval.params.catIds = [1]\n",
    "    with open(output_this_epoch + '/input_trainacc.pkl', 'wb') as f:\n",
    "        pickle.dump(coco_eval, f)\n",
    "        \n",
    "    coco_eval = COCOeval(coco_gt, coco_dt, 'bbox')\n",
    "    coco_eval.params.catIds = [2]\n",
    "    with open(output_this_epoch + '/logo_trainacc.pkl', 'wb') as f:\n",
    "        pickle.dump(coco_eval, f)\n",
    "        \n",
    "    # evaluate testing acc\n",
    "    !python train_net.py --eval-only --config-file configs/faster_rcnn_adv_eval_test.yaml \\\n",
    "                                     MODEL.WEIGHTS {weight_this_epoch} \\\n",
    "                                     OUTPUT_DIR {output_this_epoch} # Path to trained checkpoint\n",
    "    \n",
    "    gt_coco_path = 'data/benign_data/coco_perturbgt_test.json' \n",
    "    results_coco_path =  output_this_epoch + '/coco_instances_results.json' \n",
    "    coco_gt = COCO(gt_coco_path)\n",
    "    coco_dt = coco_gt.loadRes(results_coco_path)\n",
    "    \n",
    "    coco_eval = COCOeval(coco_gt, coco_dt, 'bbox')\n",
    "    with open(output_this_epoch + '/all_testacc.pkl', 'wb') as f:\n",
    "        pickle.dump(coco_eval, f)\n",
    "    \n",
    "    coco_eval = COCOeval(coco_gt, coco_dt, 'bbox')\n",
    "    coco_eval.params.catIds = [1]\n",
    "    with open(output_this_epoch + '/input_testacc.pkl', 'wb') as f:\n",
    "        pickle.dump(coco_eval, f)\n",
    "    \n",
    "    coco_eval = COCOeval(coco_gt, coco_dt, 'bbox')\n",
    "    coco_eval.params.catIds = [2]\n",
    "    with open(output_this_epoch + '/logo_testacc.pkl', 'wb') as f:\n",
    "        pickle.dump(coco_eval, f)\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./output/adv_1/logo_testacc.pkl', 'rb') as f:\n",
    "    logo_testacc = pickle.load(f)\n",
    "    \n",
    "with open('./output/adv_1/input_testacc.pkl', 'rb') as f:\n",
    "    input_testacc = pickle.load(f)\n",
    "    \n",
    "with open('./output/adv_1/all_testacc.pkl', 'rb') as f:\n",
    "    all_testacc = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./output/adv_1/logo_trainacc.pkl', 'rb') as f:\n",
    "    logo_trainacc = pickle.load(f)\n",
    "    \n",
    "with open('./output/adv_1/input_trainacc.pkl', 'rb') as f:\n",
    "    input_trainacc = pickle.load(f)\n",
    "    \n",
    "with open('./output/adv_1/all_trainacc.pkl', 'rb') as f:\n",
    "    all_trainacc = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logo_testacc.evaluate()\n",
    "logo_testacc.accumulate()\n",
    "logo_testacc.summarize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:mypy37]",
   "language": "python",
   "name": "conda-env-mypy37-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
