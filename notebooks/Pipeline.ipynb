{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overall pipeline\n",
    "1. Website element detection\n",
    "2. Credential classifier\n",
    "3. Phishpedia logo identification\n",
    "4. Layout matching model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../example.png\" style=\"width:2000px;height:350px\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2_1.datasets import WebMapper\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import funcy\n",
    "from IPython.display import clear_output\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from pycocotools import cocoeval, coco\n",
    "from detectron2.data import build_detection_test_loader, MetadataCatalog, DatasetCatalog\n",
    "import numpy as np\n",
    "import tldextract\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from credential_classifier.bit_pytorch.models import FCMaxPool\n",
    "from credential_classifier.bit_pytorch.grid_divider import read_img_reverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from phishpedia.models import KNOWN_MODELS\n",
    "from phishpedia.utils import brand_converter\n",
    "from phishpedia.inference import siamese_inference, pred_siamese\n",
    "from phishpedia.utils import brand_converter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from layout_matcher.layout_matcher_knn import bipartite_web\n",
    "from layout_matcher.misc import load_yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def element_config(rcnn_weights_path, rcnn_cfg_path):\n",
    "    \n",
    "    # merge configuration\n",
    "    cfg = get_cfg()\n",
    "    cfg.merge_from_file(rcnn_cfg_path)\n",
    "    cfg.MODEL.WEIGHTS = rcnn_weights_path\n",
    "    cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.3 # lower this threshold to report more boxes\n",
    "    \n",
    "    model = DefaultPredictor(cfg)\n",
    "    return cfg, model\n",
    "\n",
    "\n",
    "def element_recognition(img, model):\n",
    "    \n",
    "    if not isinstance(img, np.ndarray):\n",
    "        img = cv2.imread(img)\n",
    "    else:\n",
    "        img = img\n",
    "        \n",
    "    pred = model(img)\n",
    "    pred_i = pred[\"instances\"].to(\"cpu\")\n",
    "    pred_classes = pred_i.pred_classes # Boxes types\n",
    "    pred_boxes = pred_i.pred_boxes.tensor # Boxes coords\n",
    "    pred_scores = pred_i.scores # Boxes prediction scores\n",
    "\n",
    "    return pred_classes, pred_boxes, pred_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def credential_config(checkpoint):\n",
    "    \n",
    "    # load weights\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    model = FCMaxPool()\n",
    "    checkpoint = torch.load(checkpoint, map_location=\"cpu\")\n",
    "    model.load_state_dict(checkpoint[\"model\"])\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "def credential_classifier(img, coords, types, model):\n",
    "    \n",
    "    # process it into grid_array\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    grid_arr = read_img_reverse(img, coords, types)\n",
    "    assert grid_arr.shape == (9, 10, 10)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        pred = model(grid_arr.type(torch.float).to(device))\n",
    "        pred = F.softmax(pred, dim=-1).argmax(dim=-1).item() # 'credential': 0, 'noncredential': 1\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def phishpedia_config(num_classes, weights_path, targetlist_path, grayscale=False):\n",
    "    \n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    # Initialize model\n",
    "    model = KNOWN_MODELS[\"BiT-M-R50x1\"](head_size=num_classes, zero_head=True)\n",
    "    # Load weights\n",
    "    model.load_state_dict(torch.load(weights_path, map_location='cpu'))\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    '''Prediction for targetlists'''\n",
    "    logo_feat_list = []\n",
    "    file_name_list = []\n",
    "    \n",
    "    for target in os.listdir(targetlist_path):\n",
    "        if target.startswith('.'): # skip hidden files\n",
    "            continue\n",
    "        for logo_path in os.listdir(os.path.join(targetlist_path, target)):\n",
    "            if logo_path.endswith('.png') or logo_path.endswith('.jpeg') or logo_path.endswith('.jpg'):\n",
    "                if logo_path.startswith('loginpage') and not logo_path.startswith('homepage'): # skip homepage/loginpage\n",
    "                    continue\n",
    "                logo_feat_list.append(pred_siamese(img=os.path.join(targetlist_path, target, logo_path), \n",
    "                                                   model=model, grayscale=grayscale))\n",
    "                file_name_list.append(str(os.path.join(targetlist_path, target, logo_path)))\n",
    "        \n",
    "    return model, np.asarray(logo_feat_list), np.asarray(file_name_list)\n",
    "        \n",
    "\n",
    "def phishpedia_classifier(pred_classes, pred_boxes, \n",
    "                          domain_map_path,\n",
    "                          model, logo_feat_list, file_name_list, shot_path, \n",
    "                          url, \n",
    "                          ts):\n",
    "    \n",
    "    # targetlist domain list\n",
    "    with open(domain_map_path, 'rb') as handle:\n",
    "        domain_map = pickle.load(handle)\n",
    "        \n",
    "    # look at boxes for logo class only\n",
    "    logo_boxes = pred_boxes[pred_classes==0] \n",
    "    \n",
    "    # run logo matcher\n",
    "    pred_target = None\n",
    "    if len(logo_boxes) > 0:\n",
    "        # siamese prediction for logo box\n",
    "        for i, coord in enumerate(logo_boxes):\n",
    "            min_x, min_y, max_x, max_y = coord\n",
    "            bbox = [float(min_x), float(min_y), float(max_x), float(max_y)]\n",
    "            target_this, domain_this = siamese_inference(model, domain_map, \n",
    "                                                         logo_feat_list, file_name_list,\n",
    "                                                         shot_path, bbox, t_s=ts, grayscale=False)\n",
    "            # domain matcher to avoid FP\n",
    "            if not target_this is None and tldextract.extract(url).domain not in domain_this: \n",
    "                pred_target = target_this \n",
    "                break # break if target is matched\n",
    "    \n",
    "    return brand_converter(pred_target)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def layout_config(cfg_dir, ref_dir, matched_brand):\n",
    "    \n",
    "    '''get layout reference list'''\n",
    "    \n",
    "    # load cfg\n",
    "    cfg = load_yaml(cfg_dir)\n",
    "    \n",
    "    assert matched_brand in ['Amazon', 'Facebook', 'Google', 'Instagram', 'LinkedIn Corporation', 'ms_skype', 'Twitter, Inc.']\n",
    "    \n",
    "    #TODO: save pred coords or not? \n",
    "    gt_coords_arr = [] # save ref layout coords\n",
    "    gt_files_arr = [] # save ref layout filename\n",
    "    gt_shot_size_arr = [] # save ref layout screenshot size\n",
    "    \n",
    "    for template in os.listdir(os.path.join(ref_dir, matched_brand)):\n",
    "        if template.startswith('.'): # skip hidden file\n",
    "            continue\n",
    "        img = cv2.imread(os.path.join(ref_dir, matched_brand, template))\n",
    "        _, pred_boxes, _ = element_recognition(img, ele_model)\n",
    "        pred_boxes = pred_boxes.numpy()\n",
    "        gt_coords_arr.append(pred_boxes)\n",
    "        gt_files_arr.append(os.path.join(ref_dir, matched_brand, template))\n",
    "        gt_shot_size_arr.append(img.shape)\n",
    "        \n",
    "    return cfg, gt_coords_arr, gt_files_arr, gt_shot_size_arr\n",
    "        \n",
    "def layout_matcher(pred_boxes, img, \n",
    "                   gt_coords_arr, gt_files_arr, gt_shot_size_arr,\n",
    "                   cfg):\n",
    "    \n",
    "    pred_boxes = pred_boxes.numpy() if isinstance(pred_boxes, torch.Tensor) else pred_boxes\n",
    "    img = cv2.imread(img) if not isinstance(img, np.ndarray) else img\n",
    "    shot_size = img.shape\n",
    "    \n",
    "    # If the number of reported boxes is less or equal to one, no point of continue\n",
    "    if len(pred_boxes) <= 1:\n",
    "        return 0, None\n",
    "        \n",
    "    # set initial similarity = 0\n",
    "    max_s = 0\n",
    "    max_site = None\n",
    "    for j, gt_c in enumerate(gt_coords_arr):\n",
    "        similarity, sim_mat, _, _, _, _,_, _ = \\\n",
    "                    bipartite_web(gt_c, pred_boxes, gt_shot_size_arr[j], shot_size, cfg)\n",
    "        \n",
    "        if similarity >= max_s:\n",
    "            max_s = similarity\n",
    "            max_site = gt_files_arr[j]\n",
    "\n",
    "    return max_s, max_site"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ele_cfg, ele_model = element_config(rcnn_weights_path = 'output/website/model_final.pth', \n",
    "                            rcnn_cfg_path='configs/faster_rcnn_web.yaml')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_model = credential_config(checkpoint='credential_classifier/FCMax_0.05.pth.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/l/liny/anaconda3/envs/mypy37_junyang/lib/python3.7/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    }
   ],
   "source": [
    "pedia_model, logo_feat_list, file_name_list = phishpedia_config(num_classes=180, \n",
    "                                                                weights_path='phishpedia/resnetv2_rgb.pth',\n",
    "                                                                targetlist_path='phishpedia/expand_targetlist/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Expand domain map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(domain_map_path, 'rb') as handle:\n",
    "    domain_map = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for target in os.listdir('phishpedia/expand_targetlist/'):\n",
    "#     if brand_converter(target) not in domain_map.keys():\n",
    "#         print(brand_converter(target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_map['Lloyds TSB Group'] = ['lloydsbankinggroup', 'lloydsbank']\n",
    "\n",
    "class DomainDict():\n",
    "    \n",
    "    def __init__(self, domain_map):\n",
    "        self.domain_map = domain_map\n",
    "        \n",
    "    def _assign_value(self, key, value):\n",
    "        self.domain_map[key] = [value]\n",
    "    \n",
    "    def main(self):\n",
    "        key_list = ['barclays', 'VKontakte', 'lcl', 'dkb', 'la_banque_postale', 'La Poste', 'EMS',\n",
    "                    'bcp', 'barclaycard', 'smiles', 'gov_uk', 'cryptobridge', 'ieee', 'strato',\n",
    "                    'adidas', 'fsnb', 'hfe', 'cetelem', 'Commonwealth Bank of Australia', 'zoominfo',\n",
    "                    'file_transfer', 'bradesco', 'postbank', 'Airbnb, Inc.', 'SMBC', 'snapchat', \n",
    "                    'docmagic', 'Halifax Bank of Scotland Plc', 'GMX Mail', 'sicil_shop', 'cathay_bank',\n",
    "                    'otrs', 'mdpd', 'shoptet', 'tech_target', 'Yandex', 'summit_bank', 'Capitec Bank Limited',\n",
    "                    'Rakuten', 'ziggo', 'Magalu', 'wp60', 'Rabobank Nederland', 'latam', 'capital_one',\n",
    "                    'db', 'qnb', 'momentum_office_design', 'Fifth Third Bank', 'banco_de_occidente', 'htb',\n",
    "                    'orange_rockland', 'Twitter, Inc.', 'Azul', 'ameli_fr', 'typeform', 'cogeco',\n",
    "                    'banco_inter', 'itunes', 'netsons', 'Three UK', 'bahia', 'test_rite', 'anadolubank',\n",
    "                    'mbank', 'walmart', 'cloudns', 'crate_and_barrel', 'Boxberry', 'xtrix_tv', 'etrade', \n",
    "                    'taxact', 'BNP Paribas', 'ocn', 'Raiffeisen Bank S.A.', 'fnac', 'arnet_tech',\n",
    "                    'nordea', 'sunrise', 'infinisource', 'paschoalotto', 'grupo_bancolombia', 'youtube',\n",
    "                    'Banco de Cordoba', 'erste', 'cloudconvert', 'ms_bing', 'EE Limited', 'timeweb',\n",
    "                    'knab', 'sharp', 'smartsheet', 'bestchange', 'blizzard', 'ms_skype', 'eharmony']\n",
    "        \n",
    "        value_list = ['barclays', 'vk', 'lcl', 'dkb', 'labanquepostale', 'laposte', 'ems',\n",
    "                    'viabcp', 'barclaycard', 'smiles', 'gov', 'cryptobridge', 'ieee', 'strato',\n",
    "                    'adidas', 'fsnb', 'hfe', 'cetelem', 'Commonwealth Bank of Australia', 'zoominfo',\n",
    "                    'filetransfer', 'banco', 'postbank', 'airbnb', 'smbc', 'snapchat', \n",
    "                    'docmagic', 'halifax', 'gmx', 'sicilshop', 'cathaybank',\n",
    "                    'otrs', 'mps', 'shoptet', 'tech_target', 'yandex', 'summitbank', 'capitecbank',\n",
    "                    'rakuten', 'ziggo', 'magazineluiza', 'wp60', 'rabobank', 'latam', 'capitalone',\n",
    "                    'db', 'qnb', 'momentumoffice', '53', 'bancodeoccidente', 'htb',\n",
    "                    'oru', 'twitter', 'azul', 'ameli', 'typeform', 'cogeco',\n",
    "                    'bancointer', 'apple', 'netsons', 'three', 'casasbahia', 'testritegroup', 'anadolubank',\n",
    "                    'mbank', 'walmart', 'cloudns', 'crateandbarrel', 'boxberry', 'xtrixtv', 'etrade', \n",
    "                    'taxact', 'bnpparibas', 'tving', 'raiffeisen', 'fnac', 'arnettechnologies',\n",
    "                    'nordea', 'sunrise', 'infinisource', 'paschoalotto', 'grupobancolombia', 'youtube',\n",
    "                    'bancor', 'erstegroup', 'cloudconvert', 'bing', 'ee', 'timeweb',\n",
    "                    'knab', 'sharp', 'smartsheet', 'bestchange', 'blizzard', 'skype', 'eharmony']\n",
    "        \n",
    "        assert len(key_list) == len(value_list)\n",
    "        \n",
    "        for i, key in enumerate(key_list):\n",
    "            self._assign_value(key, value_list[i])\n",
    "            \n",
    "        return self.domain_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "domaindict = DomainDict(domain_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_map_after = domaindict.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(domain_map_path, 'wb') as handle:\n",
    "    pickle.dump(domain_map_after, handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Normal phishpedia without credential checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "phish30k_dir = '../phishpedia/benchmark/test30k/phish_sample_30k'\n",
    "domain_map_path = 'phishpedia/domain_map.pkl'\n",
    "write_txt = 'results/phishpedia_phish30k_0.83.txt'\n",
    "\n",
    "with open(write_txt, 'w') as f:\n",
    "    f.write('folder\\t')\n",
    "    f.write('true_brand\\t')   \n",
    "    f.write('phish_category\\t')\n",
    "    f.write('pred_brand\\t')   \n",
    "    f.write('runtime_element_recognition\\t')   \n",
    "    f.write('runtime_siamese\\n')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 11739/29496 [59:48<1:18:15,  3.78it/s]"
     ]
    }
   ],
   "source": [
    "for folder in tqdm(os.listdir(phish30k_dir)):\n",
    "        \n",
    "    phish_category = 0 # 0 for benign, 1 for phish, by default is benign\n",
    "    pred_target = None # predicted target, default is None\n",
    "    \n",
    "    img_path = os.path.join(phish30k_dir, folder, 'shot.png')\n",
    "    url = eval(open(os.path.join(phish30k_dir, folder, 'info.txt'), encoding = \"ISO-8859-1\").read())\n",
    "    url = url['url'] if isinstance(url, dict) else url\n",
    "    \n",
    "    # Element recognition module\n",
    "    start_time = time.time()\n",
    "    pred_classes, pred_boxes, pred_scores = element_recognition(img=img_path, model=ele_model)\n",
    "    ele_recog_time = time.time() - start_time\n",
    "    \n",
    "    # If no element is reported\n",
    "    if len(pred_boxes) == 0:\n",
    "        phish_category = 0 # Report as benign\n",
    "        \n",
    "    # If at least one element is reported\n",
    "    else: \n",
    "        # Phishpedia module\n",
    "        start_time = time.time()\n",
    "        pred_target = phishpedia_classifier(pred_classes=pred_classes, pred_boxes=pred_boxes, \n",
    "                                            domain_map_path=domain_map_path,\n",
    "                                            model=pedia_model, \n",
    "                                            logo_feat_list=logo_feat_list, file_name_list=file_name_list, \n",
    "                                            url=url,\n",
    "                                            shot_path=img_path,\n",
    "                                            ts=0.83)\n",
    "        siamese_time = time.time() - start_time\n",
    "\n",
    "        # Phishpedia reports target\n",
    "        if pred_target is not None:\n",
    "            phish_category = 1 # Report as phish\n",
    "\n",
    "        # Phishpedia does not report target\n",
    "        else: # Report as benign\n",
    "            phish_category = 0\n",
    "            \n",
    "    # write to txt file\n",
    "    with open(write_txt, 'a+') as f:\n",
    "        f.write(folder+'\\t')\n",
    "        f.write(brand_converter(folder.split('+')[0])+'\\t') # true brand\n",
    "        f.write(str(phish_category)+'\\t') # phish/benign\n",
    "        f.write(brand_converter(pred_target)+'\\t') if pred_target is not None else f.write('\\t')# phishing target\n",
    "        # element recognition time\n",
    "        f.write(str(ele_recog_time)+'\\t') \n",
    "        #siamese time\n",
    "        f.write(str(siamese_time)+'\\n') if 'siamese_time' in locals() else f.write('\\n') \n",
    "    \n",
    "    # delete time variables\n",
    "    try:\n",
    "        del ele_recog_time\n",
    "        del siamese_time\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- PhishIntention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phish30k_dir = '../phishpedia/benchmark/test30k/phish_sample_30k'\n",
    "domain_map_path = 'phishpedia/domain_map.pkl'\n",
    "layout_cfg_dir = 'layout_matcher/configs.yaml'\n",
    "layout_ref_dir = 'layout_matcher/layout_reference'\n",
    "layout_ts = 0.5 # TODO: set this ts\n",
    "write_txt = 'results/phishintention_phish30k_0.83.txt'\n",
    "\n",
    "with open(write_txt, 'w') as f:\n",
    "    f.write('folder\\t')\n",
    "    f.write('true_brand\\t')   \n",
    "    f.write('phish_category\\t')\n",
    "    f.write('pred_brand\\t')   \n",
    "    f.write('runtime_element_recognition\\t')   \n",
    "    f.write('runtime_credential_classifier\\t')   \n",
    "    f.write('runtime_siamese\\t')  \n",
    "    f.write('runtime_layout\\n')\n",
    "    \n",
    "for folder in tqdm(os.listdir(phish30k_dir)):\n",
    "    \n",
    "    phish_category = 0 # 0 for benign, 1 for suspicious, 2 for phish\n",
    "    pred_target = None # predicted target, default is None\n",
    "    \n",
    "    img_path = os.path.join(phish30k_dir, folder, 'shot.png')\n",
    "    url = eval(open(os.path.join(phish30k_dir, folder, 'info.txt'), encoding = \"ISO-8859-1\").read())\n",
    "    url = url['url'] if isinstance(url, dict) else url\n",
    "    \n",
    "    # Element recognition module\n",
    "    start_time = time.time()\n",
    "    pred_classes, pred_boxes, pred_scores = element_recognition(img=img_path, model=ele_model)\n",
    "    ele_recog_time = time.time() - start_time\n",
    "    \n",
    "    # If no element is reported\n",
    "    if len(pred_boxes) == 0:\n",
    "        phish_category = 0 # Report as benign\n",
    "        \n",
    "    # If at least one element is reported\n",
    "    else:\n",
    "        # Credential classifier module\n",
    "        start_time = time.time()\n",
    "        cre_pred = credential_classifier(img=img_path, coords=pred_boxes, types=pred_classes, model=cls_model)\n",
    "        credential_cls_time = time.time() - start_time\n",
    "        \n",
    "        # Credential page\n",
    "        if cre_pred == 0: \n",
    "            # Phishpedia module\n",
    "            start_time = time.time()\n",
    "            pred_target = phishpedia_classifier(pred_classes=pred_classes, pred_boxes=pred_boxes, \n",
    "                                                domain_map_path=domain_map_path,\n",
    "                                                model=pedia_model, \n",
    "                                                logo_feat_list=logo_feat_list, file_name_list=file_name_list,\n",
    "                                                url=url,\n",
    "                                                shot_path=img_path,\n",
    "                                                ts=0.83)\n",
    "            siamese_time = time.time() - start_time\n",
    "\n",
    "            # Phishpedia reports target \n",
    "            if pred_target is not None:\n",
    "                # Layout module is only built w.r.t specific brands (social media brands)\n",
    "                if pred_target not in ['Amazon', 'Facebook', 'Google', 'Instagram', \n",
    "                                     'LinkedIn Corporation', 'ms_skype', 'Twitter, Inc.']:\n",
    "                    phish_category = 2 # Report as phish\n",
    "                \n",
    "                else: \n",
    "                    layout_cfg, gt_coords_arr, gt_files_arr, gt_shot_size_arr = layout_config(cfg_dir=layout_cfg_dir, \n",
    "                                                                                       ref_dir=layout_ref_dir, \n",
    "                                                                                       matched_brand=pred_target)\n",
    "                    start_time = time.time()\n",
    "                    max_s, max_site = layout_matcher(pred_boxes=pred_boxes, img=img_path, \n",
    "                                   gt_coords_arr=gt_coords_arr, gt_files_arr=gt_files_arr, gt_shot_size_arr=gt_shot_size_arr,\n",
    "                                   cfg=layout_cfg)\n",
    "                    layout_time = time.time() - start_time\n",
    "\n",
    "                    # Success layout match\n",
    "                    if max_s >= layout_ts: \n",
    "                        phish_category = 2 # Report as phish\n",
    "\n",
    "                    # Un-successful layout match\n",
    "                    else: \n",
    "                        phish_category = 1 # Report as suspicious\n",
    "\n",
    "            # Phishpedia does not report target\n",
    "            else: # Report as benign\n",
    "                phish_category = 0\n",
    "\n",
    "        # Non-credential page\n",
    "        elif cre_pred == 1: \n",
    "            # TODO: dynamic module here\n",
    "            phish_category = 0 # Report as benign\n",
    "            \n",
    "    # write to txt file\n",
    "    with open(write_txt, 'a+') as f:\n",
    "        f.write(folder+'\\t')\n",
    "        f.write(brand_converter(folder.split('+')[0])+'\\t') # true brand\n",
    "        f.write(str(phish_category)+'\\t') # phish/benign/suspicious\n",
    "        f.write(brand_converter(pred_target)+'\\t') if pred_target is not None else f.write('\\t')# phishing target\n",
    "        # element recognition time\n",
    "        f.write(str(ele_recog_time)+'\\t') \n",
    "        # credential classifier time\n",
    "        f.write(str(credential_cls_time)+'\\t') if 'credential_cls_time' in locals() else f.write('\\t') \n",
    "        # siamese time\n",
    "        f.write(str(siamese_time)+'\\t') if 'siamese_time' in locals() else f.write('\\t') \n",
    "        # layout time\n",
    "        f.write(str(layout_time)+'\\n') if 'layout_time' in locals() else f.write('\\n') \n",
    "        \n",
    "    # delete time variables\n",
    "    try:\n",
    "        del ele_recog_time\n",
    "        del credential_cls_time\n",
    "        del siamese_time\n",
    "        del layout_time\n",
    "    except:\n",
    "        pass\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Test single site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = 'datasets/train_imgs/Amazon.com Inc.+2020-08-16-15`54`25.png'\n",
    "pred_classes, pred_boxes, pred_scores = element_recognition(img=img_path, model=ele_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_pred = credential_classifier(img_path, pred_boxes, pred_classes, cls_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3123,)\n"
     ]
    }
   ],
   "source": [
    "domain_map_path = 'phishpedia/domain_map.pkl'\n",
    "\n",
    "pred_target = phishpedia_classifier(pred_classes=pred_classes, pred_boxes=pred_boxes, \n",
    "                                    domain_map_path=domain_map_path,\n",
    "                                    model=pedia_model, \n",
    "                                    logo_feat_list=logo_feat_list, file_name_list=file_name_list, \n",
    "                                    shot_path=img_path,\n",
    "                                    url='https://www.kkk.com',\n",
    "                                    ts=0.83)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "layout_cfg, gt_coords_arr, gt_files_arr, gt_shot_size_arr = layout_config(cfg_dir='layout_matcher/configs.yaml', \n",
    "                                                                   ref_dir='layout_matcher/layout_reference', \n",
    "                                                                   matched_brand=pred_target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "max_s, max_site = layout_matcher(pred_boxes=pred_boxes, img=img_path, \n",
    "                                 gt_coords_arr=gt_coords_arr, gt_files_arr=gt_files_arr, gt_shot_size_arr=gt_shot_size_arr,\n",
    "                                 cfg=layout_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check = cv2.imread(img_path)\n",
    "# for j, box in enumerate(pred_boxes):\n",
    "#     cv2.rectangle(check, (box[0], box[1]), (box[2], box[3]), (36, 255, 12), 2)\n",
    "#     cv2.putText(check, str(pred_classes[j].item()), (box[0], box[1]), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
    "\n",
    "# plt.figure(figsize=(20,20))\n",
    "# plt.imshow(check[:, :, ::-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(result_path, gt_type):\n",
    "    assert gt_type in ['phish', 'benign'] # gt type is either phish/benign\n",
    "    result = open(result_path).readlines()\n",
    "    result_df = pd.DataFrame(result)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
